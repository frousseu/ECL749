---
title: "ECL749 Ateliers R"
author: "François Rousseu"
date: "Hiver 2020"
output:
  html_document:
    depth: 4
    fig_height: 5
    fig_width: 6
    number_sections: no
    toc: yes
    toc_depth: 5
    toc_float:
      collapsed: yes
      smooth_scroll: no
---

<script>
    $(document).ready(function() {
      $items = $('div#TOC li');
      $items.each(function(idx) {
        num_ul = $(this).parentsUntil('#TOC').length;
        $(this).css({'text-indent': num_ul * 20, 'padding-left': 0});
      });

    });
</script>


<style>

pre.r {
    background-color: #CCCCCC!important;
    border-color: #EEEEEE!important;
    font-size: 14pt;
}

pre code {
  font-size: 11pt;
}

body {
  font-size: 14pt;
}

.main-container {
    max-width: 1300px !important;
}

#TOC {
  font-size: 12pt;
  border-color: white;
}

.list-group-item.active:focus{
    z-index: 2;
    color: darkgreen;
    background-color: #EEEEEE;
    border-color: red;
    font-weight: bolder;
    font-color: red;
}

.list-group-item.active:hover {
    z-index: 2;
    color: darkgreen;
    background-color: #EEEEEE;
    border-color: red;
    font-weight: bolder;
    font-color: red;
}

.list-group-item.active{
    z-index: 2;
    color: darkgreen;
    background-color: #EEEEEE;
    border-color: red;
    font-weight: bolder;
    font-color: red;
}

h1.title {
  margin-top: 120px;
  font-size: 42px;
  color: DarkGreen;
  font-weight: bold;
}
h1 {
  padding-top: 50px;
  font-size: 42px;
  color: DarkGreen;
  font-weight: bold;
}
h2 {
  padding-top: 50px;
  font-size: 36px;
  color: DarkGreen;
  font-weight: bold;
}

h3 {
  padding-top: 10px;
  font-size: 32px;
  color: DarkGreen;
  font-weight: bold;
}
h4 {
  font-size: 28px;
  color: DarkGreen;
  font-weight: bold;
}
h5 {
  font-size: 26px;
  color: DarkGreen;
  font-weight: bold;
}

</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, tidy=TRUE, error=TRUE)
```

<br>

# Atelier 1

## R et RStudio

[R](https://cran.r-project.org/) est un langage et un environnement pour le calcul scientifique et les graphiques. Il peut cependant être utilisé pour bien d'autres choses puisqu'il s'agit avant tout d'un langage de programmation.


[RStudio](https://www.rstudio.com/) est en quelque sorte un éditeur de texte avancé facilitant l'utilisation et la communication avec R. À l'intérieur de cette interface, vous pouvez créer un script avec vos lignes de commande qui pourront être envoyées dans la console R. Il y a beaucoup de fonctionnalités dans RStudio et ces dernières sont décrites dans cette *cheat sheet*: [RStudio IDE Cheat Sheet](https://www.rstudio.com/resources/cheatsheets/#ide) 

<br>

## Opérations et objets de base 

R peut être utilisé comme une simple calculatrice!

```{r}

3*4
13/3
3^3

```

<br>

On peut également assigner des objets à des symboles avec l'opérateur `<-` et concaténer des nombres ensemble avec la fonction `c` pour créer un vecteur, un objet à **1 dimension**. Par la suite, on peut effectuer des opérations vectorisées, i.e. à chaque élément du vecteur. 

```{r}
v1<-c(1,2,3,4,5,6,7,8,9)  
v1
v2<-c(10,10,10,10,10,10,10,10,10)
v1+v2
v1*v2+1
```

<br>

On peut aussi coller ces deux vecteurs ensembles pour créer une matrice (`matrix`), un objet à **2 dimension**. 

```{r}

m<-cbind(v1,v2)  #! Colle deux vecteurs ensemble
m
```

<br>

Une matrice est composée d'un même type de valeurs, soit numérique, caractère ou logique. Plus général, un `data.frame` peut contenir plusieurs types de valeurs. C'est l'équivalent d'un tableau de données dans Excel. 

```{r}

d<-data.frame(v1,v2,z=c("a","b","c","d","e","f","g","h","i"))
d

```

<br>

Les listes peuvent contenir tout type d'objets et sont des objets à une dimension.

```{r}

l<-list(v1,m,d)
l

```

<br>

### Type de données

Les principaux types de données ou de valeurs dans R sont:

```{r}
x<-c(1,2,3,4,5)
class(x)
```

```{r}
x<-c("bonjour","allo","bye")
class(x)
```

```{r}
x<-c(TRUE,TRUE,FALSE)
class(x)
```

Il y a également le type de données correspondant à un facteur (**factor**),

```{r}
x<-c("bonjour","allo","bye","allo","bye")
x<-factor(x)
class(x)
```

Si on affiche cet objet dans la console:

```{r}
x
```

Les *factors* sont des vecteurs de catégories ayant chacune une étiquette et représentées de façon interne par des entiers. Par défaut, les étiquettes sont numérotées par ordre alphabétique. 

<br>

### Objets de données

- `vector` (1 dimension, 1 type de données)
- `matrix` (2 dimensions, 1 type de données)
- `data.frame` (2 dimensions, tout type de données)
- `list` (1 dimension, tout type d'objets)
- `array` (3 dimension, un type de données)

<br>

### Objets et assignation

Tout ce qui est contenu dans une session R est un **objet** qui porte un nom. Lorsque l'on modifie un objet, il faut se rappeler d'assigner le résultat afin de le conserver dans le même objet ou dans un nouvel objet. Par exemple, affichons le contenu de v1:

```{r}
v1
```

Maintenant, ajoutons une valeur à v1:

```{r}
v1+100
```

Le résultat s'affiche, mais l'objet n'a toujours pas changé:

```{r}
v1
```

L'objet `v1` n'a toujours pas changé, car il faut assigner le résultat à un nouvel objet ou à l'objet v1 en "écrasant" l'ancien objet v1.

```{r}
v1<-v1+100
v1
```

Tout ce qui est contenu dans une session R est un **objet** qui porte un nom.

<br>

## Accéder aux données

L'accès aux données se fait par l'intermédiaire de l'indexation qui est le processus par lequel on accède aux données à l'intérieur d'un objet. Pour ce faire, on utilise généralement les opérateurs `[` et `$` avec différentes conditions pour établir notre sélection.

<br>

### Avec un vecteur

```{r}
v1
```

On accède au 3e élément du vecteur.

```{r}
v1[3]
```

On accède à tous les éléments supérieurs à 105.

```{r}
v1[v1>105]
```

On accède à tous les éléments supérieurs à 105 et inférieurs ou égal à 108.

```{r}
v1[v1>105 & v1<=108]
```

<br>

### Avec un `data.frame`

Un `data.frame` est un objet en 2 dimensions qui contient des lignes et des colonnes `d[i, j]`.

```{r}
d
```

On sélectionne les lignes 4 à 6 du `data.frame`.

```{r}
d[4:6,]
```

On sélectionne les colonnes 1 et 3 du `data.frame`.

```{r}
d[,c(1,3)]
```

On sélectionne la colonne nommée `z`. 

```{r}
d$z
```

On sélectionne toutes les lignes où `v1` est supérieur à 7. 

```{r}
d[d$v1>7,]
```

<br>

### Avec une liste

Avec les "`[`" simples, on accède aux éléments de la liste qui sont aussi retournés sous forme de liste.

```{r}
l[1]
```

Avec les doubles "`[[`", on accède directement à un seul élément contenu dans la liste.

```{r}
l[[1]]
```

On peut également accéder aux éléments de la liste par leur nom si cette liste est nommée.
```{r}
l$v1
```

Puisque la liste n'est pas nommée, la valeur `NULL` nous est retournée.

```{r}
names(l)<-c("allo","bonjour","bye")
l$bye
```

<br>

## Fonctions

On retrouve également dans R des objets qui sont des **fonctions**. Les fonctions peuvent être appliquées à des objets pour obtenir des résultats. On applique les fonctions aux objets en utilisant les parenthèses `()`, contrairement aux crochets `[]` qui servent à l'indexation. Par exemple, `c` est une fonction qui permet de coller des valeurs ensembles dans un vecteur.

```{r}
temp<-c(37,54,79,23,3,101,4)
```

La fonction `mean` permet de calculer des moyennes et la fonction `sd` des écarts-types.

```{r,results="hold"}
mean(temp)
sd(temp)
```

La fonction `rep` permet de répéter des valeurs. Ici, on répète le vecteur `1:2` 5 fois.

```{r}

rep(1:3,times=5)

```

<br>

### Arguments

Ceci permet d'introduire les *arguments* qui composent les fonctions. On pourrait aussi utiliser l'argument `length.out` ou `each` pour modfifier la façon dont les valeurs sont répétées.

```{r,results="hold"}

rep(1:3,each=5)
rep(1:3,length.out=5)

```

En général, la majorité des arguments d'une fonction ont des valeurs par défaut. Par exemple, les valeurs par défaut de `rep` sont `times = 1`.

```{r}

rep(1:3)

```

Par défaut, le premier élément listé à l'intérieur d'une fonction est l'objet auquel on veut l'appliquer et correspond au premier argument de la fonction. Cet argument n'a généralement par besoin d'être nommé. Par contre, il est souvent préférable ou nécessaire de nommer les éléments suivants. Si ceux-ci ne sont pas nommés, l'ordre dans lequel ils sont donnés sera utilisé pour les associer aux arguments correspondant.

<br>

### Opérateurs

Certaines fonctions sont représentées par des opérateurs. En voici quelques exemples.


```{r}

3==4 # égal
3+4 # addition
TRUE&TRUE # "et" logique
TRUE&FALSE # "et" logique
3==4 | 3==5 # "ou" logique
c(3,4)%in%c(4,5,6,7) # élément du vecteur 1 contenule vecteur 2
3:10 # crée un vecteur avec tous les entiers de 3 à 10

```

<br>

## Importation des données

### Le répertoire courant

Lorsqu'on débute avec R, c'est souvent à cette première étape cruciale qu'on a des problèmes! Premièrement, R travaille dans un seul dossier à la fois, c'est-à-dire que la base de données doit être dans le bon dossier, appelé **répertoire courant** (*Working Directory*). Pour dire à R quel est ce dossier, on va dans RStudio sous l'onglet *Session > Set Working Directory*. On doit généralement faire cette opération à chaque début de session de travail dans R, à moins que RStudio s'ouvre par défaut au bon endroit. On peut également inspecter le répertoire courant à l'aide de la fonction `getwd`.

```{r}

getwd()

```

Pour s'assurer que notre base de données se trouve bien à cet endroit, on peut utiliser la fonction `list.files`.

```{r}

list.files()

```

<br>

### Les données manquantes (NA)

Avant d'importer des données, il est nécessaire d'aborder la gestion des données manquantes par R. Les données manquantes sont toujours représentées par des `NA`, que ce soit dans les vecteurs ou dans les tableaux de données. Lorsqu'on veut importer des données avec des cellules vides, il est souvent nécessaire de remplacer les cellules vides par des `NA`. Parfois, il est possible de dire à une éventuelle fonction que les cellules vides correspondent à des `NA`.

<br>

### Les fonctions d'importation

Il existe plusieurs méthodes pour importer des données dans R. La façon classique est par l'intermédiaire de la fonction `read.table`. Cette fonction prend des fichiers textes (*.txt*) qui doivent répondre à plusieurs critères:

- Il ne doit y avoir aucun espace dans les noms des différentes variables et dans les éléments de la base de données. Par exemple, «bon à modéré» va créer des problèmes. On devrait plutôt écrire "bon.à.modéré" ou "bon_à_modéré". Encore mieux serait d'éviter les accents ou d'utiliser un code.

- **AUCUNE** cellule ne doit être vide. Si une cellule est vide ou si on a écrit un commentaire au lieu d'un nombre, on écrit `NA` dans la cellule. Autrement, R produira un message d'erreur puisqu'il considérera qu'une ligne du tableau est incomplète.

- Il faut généralement utiliser le point plutôt que la virgule pour les nombres décimaux (à moins de le spécifier dans les arguments). Autrement, une virgule sera considérée comme étant du caractère.

- Par défaut, les colonnes contenant du texte ou tout caractère ne pouvant pas être interprétés comme un chiffre seront considérées comme étant des colonnes contenant du texte (*character*) et seront automatiquement converties en *factor* par les fonctions d'importation de base comme `read.table`. Pour éviter ceci, il est possible de spécifier l'argument `stringsAsFactors = FALSE`.

Les messages d'erreurs sont très très fréquents lors de l'importation d'une nouvelle base de données. Il s'agit d'être en mesure de bien les interpréter et d'observer ces quelques règles de base.

<br>

Plusieurs autres fonctions sont disponibles selon le format des données (`read.delim`, `read.csv`, etc.). Le format *.csv* est souvent le plus pratique, car il réduit les risques de problèmes lors de l'importation en raison de la délimitation des cellules. Il est également possible d'utiliser le package **readxl** pour lire directement des fichiers `.xlsx`. Bien qu'étant la façon classique d'importer des données, la fonction `read.table` est assez capricieuse... On peut également exporter des données avec les fonctions `write.table` ou `write.csv`.

Voici les fonctions de base les plus souvent utilisées pour importer des données:

- `read.table` : pour des fichiers *.txt*

- `read.csv` : pour des fichiers *.csv* (c'est la meilleure façon)

- `read_excel` : fonction du package **readxl** pour des fichiers *.xlsx*

<br>

Voici un exemple:
```{r, results="hold"} 
getwd()
d<-read.table("data.txt",header=TRUE)
```

Le code précédent se base sur le fait que le fichier de données est dans le répertoire courant. Si ce n'était pas le cas, il serait aussi possible de spécifier l'emplacement exact du fichier à charger en indiquant le chemin au complet. De cette façon, il est possible d'aller chercher des bases de données ailleurs que dans le répertoire courant.

```{r} 
d<-read.table("C:/Users/rouf1703/Documents/UdeS/GitHub/ECL749/lab/data.txt",header=TRUE)
```

<br>

### Inspection des données

Il existe plusieurs fonctions pour inspecter les données suite à leur importation ou pour inspecter un `data.frame`. Lors de l'importation de données, il est fortement recommandé de faire un peu d'inspection pour s'assurer que le tout est conforme à nos attentes. 

La fonction `dim` permet de connaître le nombre de lignes (*i*) et le nombres de colonnes (*j*) d'un `data.frame`.

```{r} 
dim(d)
```

La fonction `head` permet d'observer les 6 premières lignes.

```{r} 
head(d)
```

<br>

La fonction `str` permet d'inspecter le type de données dans chacune des colonnes.

```{r} 
str(d)
```

<br>

La fonction `summary` permet de résumer les données dans chacune des colonnes.

```{r} 
summary(d)
```



<br>

## Exercice

Ce premier exercice consiste à importer une base de données en format *.txt*. Cette base de données contient des mesures morphométriques d'une espèce de bruant (un oiseau). Vous pouvez la télécharger à l'adresse suivante:

[https://raw.githubusercontent.com/frousseu/ECL749/master/data/sparrows.txt](https://raw.githubusercontent.com/frousseu/ECL749/master/data/sparrows.txt)

Vous devez utiliser le bouton droit de la souris pour sauvegarder le contenu de la page dans un fichier *.txt*.

Par la suite, vous devez calculer la longueur moyenne de la corde de l'aile (**wingcrd**) et de la masse (**wt**) et effectuez un graphique mettant en relation les deux mesures. La fonction `plot` devrait vous être utile. 

Vous devez également utiliser la fonction `table` pour compter le nb d'observations de mâles et de femelles et apprendre le fonctionnement de la fonction `boxplot` pour comparer la variabilité de la masse chez les deux sexes.

Finalement, effectuez et interprétez un test de t pour comparer la masse chez les deux sexes. Ici, la fonction `subset` pourrait être utile, mais il est possible de s'en sortir en utilisant seulement l'indexage (les `[ ]`).

Il y a peut-être quelques petits problèmes avec la base de données...

<br><br><br>

### Solution 

On télécharge le fichier *sparrows.txt* avec le bouton de droit en appuyant sur le bouton *raw*. On met ce fichier à un endroit correspondant au répertoire courant ou on change le répertoire courant pour celui de l'emplacementr du fichier. Vous pouvez aussi utiliser le menu de RStudio *Session > Set Working Directory > Choose Directory*. Remarquez que la ligne `setwd("chemin/vers/le/fichier.txt")` va s'écrire dans la console. Le mieux serait d'inclure cette ligne dans votre script. Remarquez qu'il serait aussi possible d'écrire le chemin vers le fichier au long au lieu de seulement inscrire le nom du fichier (entre guillemets) pour la fonction `read.table`.

```{r, error=TRUE}

setwd("C:/Users/rouf1703/Desktop")
d<-read.table("sparrows.txt",header=TRUE)

```

Le message d'erreur retourné nous dit qu'il manque un élément à la ligne 83 du tableau de données. Il est important de bien lire les messages d'erreur, car la plupart du temps, ils nous donnent une indication du problème. Le plus simple est probablement d'aller dans le tableau de données et de remplacer manuellement la cellule manquante par un `NA`. 

```{r, echo=FALSE,eval=TRUE,include=TRUE}
# This reads the corrected file with the NA added
d<-read.table("C:/Users/rouf1703/Desktop/sparrows2.txt",header=TRUE)
```

Maintenant qu'on a les données, on peut calculer les moyennes des deux variables *wingcrd* et *wt*.

```{r, hold=TRUE}

mean(d$wingcrd)
mean(d$wt)

```

On obtient un `NA` pour la première moyenne et un message d'avertissement pour la seconde. Inspectons ce que contient le vecteur `d$wingcrd` pour comprendre pourquoi un `NA` est retourné. On voit que le vecteur contient une valeur de `NA` et par défaut, la fonction `mean` retourne un `NA` (`?mean`). Pour ignorer le `NA`, on doit utiliser l'argument `na.rm = TRUE` de la fonction `mean`.

```{r, hold=TRUE}

mean(d$wingcrd,na.rm=TRUE)
mean(d$wt,na.rm=TRUE)

```

On obtient une valeur pour la longueur de l'aile, mais on obtient toujours un message d'erreur pour la masse. Inspectons le contenu de *d$wt* pour comprendre un peu mieux.

```{r}

d$wt

```

```{r, echo=FALSE,eval=TRUE,include=TRUE}
# This reads the corrected file with comma replaced with a dot
d<-read.table("C:/Users/rouf1703/Desktop/sparrows3.txt",header=TRUE)
```

On semble avoir des valeurs, mais on voit également que le résultat indique qu'il y a `48 Levels` dans notre vecteur. Ceci indique que R a transformé la colonne en **facteur**. Par défaut, la fonction `read.table` convertit en facteur toute colonne qui ne semble pas être composée de données numériques ou logiques. Ceci est le cas pour les données de type `character`. Puisqu'une virgule se trouve quelque part dans notre série de valeurs, R a considéré que ces données étaient des facteurs et a convertit le tout en conséquence. Pour comprendre un peu mieux l'utilisation des facteurs avec R, consultez la section d'aide sur la fonction `?factor`. En bref, les `factor` sont des valeurs comportant une étiquette (la plupart du temps un caractère) et étant représentées par un entier allant de 1 au nombre d'étiquettes différentes. Pour éviter ce problème, le plus simple serait de retourner dans le tableau de données initiales et de changer la virgule pour un point pour que la colonne soit interprétée comme une colonne de valeurs numériques. 

Maintenant que nous avons toutes nos valeurs, nous pouvons calculer les deux moyennes et effectuer un graphique représentant le lien entre ces deux mesures avec la fonction `plot`.

```{r, hold=TRUE}

mean(d$wingcrd,na.rm=TRUE)
mean(d$wt,na.rm=TRUE)
plot(d$wingcrd,d$wt)

```

Sans surprise, les deux variables semblent positivement corrélées. Par la suite, on utilise la fonction `table` pour compter le nombre d'observations des deux sexes. 

```{r}

table(d$Sex)

```

La fonction `boxplot` nous permet de comparer la masse chez les deux sexes.

```{r}

boxplot(wt~Sex,data=d)

```

Remarquez la forme des arguments de la fonction `boxplot`. Ceux-ci sont donnés sous forme de formule (`?formula`) et non sous forme de caractères entre guillemets. Avec l'argument `data`, la fonction `boxplot` va chercher dans le `data.frame` les noms de colonnes correspondants. Cette façon de spécifier les variables sous forme de formule sera beaucoup utilisée lorsque nous ferons des modèles. 

Par la suite, nous devons trouver le moyen de séparer les mâles des femelles afin d'effectuer notre test de t. Pour ce faire, il est possible d'utiliser la fonction `subset` ou simplement d'utiliser l'indexage. Les 4 lignes suivantes produisent les mêmes objets.

```{r}

m<-subset(d,subset=Sex=="m")
f<-subset(d,subset=Sex=="f")

m<-d[d$Sex=="m",]
f<-d[d$Sex=="f",]

```

Un peu comme dans la fonction `boxplot`, il n'est pas nécessaire d'utiliser les guillemets ou le `$` puisque la fonction `subset` cherchera dans le `data.frame` soumis pour trouver la colonne demandée (ici, *Sex*). Avec l'indexage régulier, il faut toutefois identifé où se trouve la colonne avec `d$Sex`. Par la suite, on effectue notre test de t.

```{r}
t.test(m$wt,f$wt)
```

La valeur de *p* est inférieure à 0.05 et l'intervalle de confiance a des bornes inférieure et supérieures positives, on conclut donc que les mâles ont une masse supérieure aux femelles et que cette différence est de l'ordre de 1 ou 2 grammes.

Plutôt que de séparer les mâles et les femelles en deux `data.frame`, il serait encore plus efficace d'utiliser une formule pour spécifier notre test de t.

```{r}
t.test(wt~Sex,data=d)
```

Les résultats sont identiques. Cependant, le sexe de référence a été inversé entre les deux façons de formuler le test de t.

## Retour

### Script et console

Un script R est un fichier *.R* où on écrit le code qu'on veut conserver et à partir duquel on peut envoyer les différentes lignes de codes vers la console R. La console est l'endroit où sont évalué les différentes commandes et où les objets de la session R sont contenus. On peut écrire directement dans la console pour envoyer des commandes, mais il est préférable d'écrire ces commandes dans un script lorsqu'on veut conserver les commandes importantes. 

### Insertion de commentaires

Pour insérer des commentaires dans un script, on utilise le dièse `#` (ou, pour utiliser un langage plus moderne, le *hashtag*...). Ces lignes ne seront pas interprétées lorsque'elle seront envoyées à la console.

```{r}
# Voici un commentaire qui ne sera pas interprété comme une commande
```

### Environnement de travail

Il est possible de sauvegarder à la fois un script (un fichier *.R*) qui contient du code ou un environnement de travail (un fichier *.RData*, le *Workspace*) qui contient les objets créés dans l'environnement. En général, il est beaucoup plus utile de conserver un script avec le code important puisque celui-ci peut être relancé à nouveau et c'est celui qui contient le travail important. Sauvegarder l'environnement de travail n'est généralement utile que si on crée des objets longs à produire ou si on veut partager des objets avec d'autres personnes par exemple. Pour sauvergarder l'environnement de travail, on peut aller sous le menu de RStudio et faire *Session > Save Workspace As*. Il est également possible de conserver l'historique des commandes, mais ceci n'est pas très utile puisque cela conserve l'ensemble des commandes qui ont été envoyées à la console, y compris les commandes contenant des erreurs.


### Importation de données

Comme vous avez pu le constater, l'importation de données avec `read.table` peut être ardue lorsque l'on débute. Pour éviter beaucoup de problème, une inspection préalable de la base de données est souvent nécessaire. Le message d'erreur le plus commun est probablement celui-ci.

```{r,error=TRUE}
d<-read.table("Sparrows.txt",header=TRUE)
```

Ce message indique que soit on a fait une erreur dans le nom du fichier, soit le fichier ne se trouve pas dans le répertoire courant. Dans cet exemple, il s'agit d'une erreur dans le nom du fichier. Remarquez également l'utilisation de l'argument `header` pour spécifier que la première ligne du tableau de données contient les noms de colonnes. Un autre argument très utilisé est `stringsAsFactors = FALSE` qui permet de spécfier que les données de type caractère ne doivent pas être automatiquement converties en `factor`.

#### Nom du fichier / chemin

Avec la plupart des fonctions d'importation, on peut soit donner le nom du fichier (avec l'extension) si celui-ci se trouve dans le répertoire courant, soit donner le chemin complet vers où le fichier se trouve.

```{r,eval=FALSE,include=TRUE}
d<-read.table("C:/Users/rouf1703/Desktop/sparrows.txt",header=TRUE)
```

De cette façon, on s'affranchit du répertoire courant, car on indique directement à R où aller chercher le fichier. Ceci peut être très utile lorsqu'on ne veut pas changer le répertoire courant à chaque session ou si on a des fichiers classés à différents endroits sur l'ordinateur.

#### Autres fonctions d'importation

L'importation de fichiers *.txt* est la base, mais il est souvent plus facile d'utiliser le format *.csv* et la fonction `read.csv`. Ce format cause généralement moins de problèmes avec les cellules vides et la séparation entre les différentes colonnes est souvent moins ambigue qu'avec les espaces ou les tabulations.

Il est également possible de lire directement dans un fichier Excel avec les packages [readxl](https://cran.r-project.org/web/packages/readxl/index.html) et [xlsx](https://cran.r-project.org/web/packages/xlsx/index.html), mais je vais vous laisser le soin d'étudier ces possibilités.

### Inspection des données

Une fois qu'une base de données est importée, plusieurs fonctions peuvent être utilisées pour inspecter un `data.frame`. Les plus communes sont les fonctions `head`, `str`, `summary`. Voici des exemples.

```{r,hold=TRUE}
head(d)
str(d)
summary(d)
```

La fonction `head` affiche les 6 premières lignes d'un `data.frame`. La fonction `str` liste les colonnes et informe sur le type de données dans chacune de celles-ci. La fonction `summary` calcule un résumé de l'information dans chaque colonne qui dépend du type de données.

Il est également possible d'inspecter les objets en utilisant l'onglet *Environment* dans RStudio et en cliquant sur les différents objets.

### Les guillemets

Les guillemets sont régulièrement utilisés dans R pour indiquer des valeurs correspondant à des caractères. Par exemple, le nom d'un fichier doit être donné entre guillemets à la fonction `read.table`. Pour certaines fonctions (e.g. `library`, `subset`) et pour les fonctions avec des formules et un argument `data`, les guillemets ne sont pas nécessaires. Il peut être frustrant au début de distinguer entre ces deux possibilités, mais on finit par s'y habituer. Encore une fois, se référer au fichier d'aide!

### `=` vs. `==`

Le signe d'égalité simple `=` est la plupart du temps utilisé pour spécifier un argument à une fonction. Il peut parfois être utilisé pour faire des assignations au lieu de la flèche d'assignation `<-`, mais on recommande d'éviter cette pratique. Le double `==` est utilisé comme une fonction pour tester l'égalité entre des valeurs ou des objets.

### Les facteurs

Étudions un peu plus les facteurs. Comme dit plus haut, un `factor` est un vecteur avec différents niveaux ayant une étiquette et représenté de façon interne par des entiers. Par défaut, les étiquettes sont classées par ordre alphabétique pour établir la représentation en entier. En général, avant de faire une analyse statistique comportant des facteurs, il faut s'assurer que nos variables catégoriques sont converties en tant que tel avec les fonctions `factor` ou `as.factor`. Ceci est particulièrement important pour les facteurs représentés par des valeurs numériques. Autrement, les modèles risquent de considérer ces variables comme numériques.

```{r}
v<-c("c","b","b","a","a","a")
v<-factor(v)
v
```

```{r,error=TRUE}
as.numeric(v)
as.character(v)
levels(v)
mean(v)
v+1
```

### Consultez l'aide!

Avant d'utiliser une fonction, il faut se rappeler que c'est toujours un bon réflexe de consulter l'aide et particulièrement les exemples qui montrent souvent comment utiliser la fonction et ses arguments. 

<br><br><br>

# Atelier 2

<br>

## Sauvegarde du travail

Suite à une session de travail dans R, il est généralement possible de sauvegarder deux types d'éléments soit un fichier de commande (ou un script R, *nomdufichier.R*) ou l'environnement de travail (un *workspace*, *nomdufichier.RData*). 

Le premier sert à conserver les lignes de commandes et le second à conserver les objets générés dans la session de travail. En général, le plus important est de sauvegarder les lignes de commandes utilisées. Pour ce faire, il faut cliquer sur le bouton disquette en haut à gauche du panneau des scripts. Par la suite, il est possible d'envoyer à nouveau nos lignes de commande pour produire la tâche désirée.

<br>

### Script .R

- Fichier de commande ou script permettant de refaire les analyses. **C'est ce qui est important à conserver!**

- On peut ouvrir un script *.R* avec le menu de RStudio en faisant: *File > Open File* ou en utilisant le bouton d'ouverture de dossier.

- On peut insérer des commentaires dans un script avec le symbole `#` de cette façon:

```{r, eval=TRUE} 
# permet de répéter 2 fois le vecteur allant de 1 à 5
rep(1:5,2)
```

<br>

### .RData

- Environnement de travail avec les objets de la console R au moment de la sauvegarde (mais ne contient pas les lignes de commandes!)

- On peut le conserver au besoin en utilisant la fonction `save` ou en suivant dans le menu de RStudio  *Session > Save Workspace As*

- On peut ouvrir un environnement de travail avec la fonction `load` ou en faisant *Session > Load Workspace*

<br>

## Aide

Dès que l'on se met à jouer avec R, il est rapidement essentiel d'aller inspecter son fichier d'aide. Ceci peut être tout aussi éclairant que frustrant! Mais c'est généralement éclairant et absolument essentiel. Pour accéder à l'aide sur la fonction `rep`, on n'a qu'à taper `?rep`.

##### Section *Description*

Cette section contient une courte description de ce que fait la fonction.

##### Section *Usage*

Cette section montre comment la fonction est utilisée et liste également la plupart du temps les valeurs par défaut des arguments.

##### Section *Arguments*

Cette section explique l'utilisation de chacun des arguments de la fonction et donne également les valeurs par défaut.

##### Section *Details*

Cette section donne parfois des détails plus précis par rapport à l'utilisation de la fonction.

##### Section *Value*

Cette section décrit la valeur retournée par la fonction.

##### Section *See Also*

Cette section donne des suggestions concernant d'autres fonctions jouant un rôle similaire.

##### Section *Examples*

Cette section très utile donne des exemples d'utilisation de la fonction. Ces exemples peuvent être copiés et collés directement dans votre session R afin d'étudier l'utilisation de la fonction. Pour bien comprendre l'utilisation d'une fonction, cette section n'est pas à négliger! 

<br>

## Packages

Les packages sont des banques de fonctions destinées à des tâches spécifiques. Plusieurs packages de bases sont installés avec R, mais il existe plusieurs milliers de packages de toutes sortes. Pour installer un package donné sur son ordinateur (par exemple le package **spatstat**, pour les statistiques spatiales), on utilise la fonction `install.packages` de cette façon :
 
```{r, eval=FALSE} 
install.packages("spatstat")
```

Dépendamment de si on travaille avec R ou RStudio, on demande parfois de sélectionner un miroir CRAN à partir duquel le téléchargement sera fait. Une fois le package installé, il faut activer le package dans notre session de travail R. Pour les packages spéciaux qui ne font pas partie des packages de base de R, on doit les activer à chaque session de travail avec la fonction `library`.

```{r, eval=FALSE}
library(spatstat)
```

Remarquez que l'utilisation des guillemets "" est optionnelle dans la fonction library, mais c'est rarement le cas dans les autres fonction lorsque l'on réfère à un nom.

Il est fréquent d'utiliser une fonction dans R sans avoir préalablement chargé le package la contenant. Dans ce cas, un message d'erreur nous dit que la fonction utilisée n'existe pas. Ceci peut également résulter d'une mauvaise orthographe de la fonction.

## Les graphiques

La principale fonction pour créer des graphiques est la fonction `plot`. Certains arguments de cette fonction sont décrits dans le fichier d'aide de la fonction (`?plot`), mais la plupart des arguments sont décrits dans la page de la fonction `?par` qui sert à établir les paramètres graphiques utilisés. Voici quelques paramètres (ou arguments) graphiques fréquemment utilisés. Notez la fonction `par` et l'argument `mfrow` qui sert à créer une fenêtre graphique 2 x 2. L'argument `mar` de la fonction `par` permet de modifier la largeur des marges du graphique (bas, gauche, haut et droite). 

```{r,error=TRUE,fig.height=7,fig.width=8}
par(mfrow=c(2,2),mar=c(5,5,2,2))

plot(1:20,1:20,pch=1:20,col="black",cex=2) # graphique 1

plot(1:20,1:20,pch=16,col=1:20,cex=3) # graphique 2

plot(1:20,1:20,pch=1,col="red",cex=1:20/4) # graphique 3

plot(1:20,1:20, xlim=c(5,15),ylim=c(5,15)) # graphique 4
points(1:20,1:20+1,pch=2,col="magenta")
lines(1:20,1:20+2,lwd=2,lty=1,col="blue")
text(12,6,labels="Voici du texte",font=2)

```

La fonction `plot` permet d'établir la fenêtre graphique. Par la suite, on peut ajouter des points, des lignes ou du texte à un graphique à l'aide des fonctions `points`, `lines` et `text`. Notez que ces fonctions ne permettent pas de créer ou d'ouvrir un graphique. Elles ne permettent que d'ajouter des éléments sur un graphique déjà exsitant. La fonction `legend` permet d'identifier des éléments sur un graphique.

```{r,error=TRUE,fig.height=7,fig.width=8}
par(mfrow=c(1,1))

plot(1:10,1:10,pch=16,col="red",xlim=c(0,10),ylim=c(0,10),xlab="Valeurs X",ylab="Valeurs Y",main="Voici un titre")
points(1:10,1:10-1,pch=16,col="blue")
legend("topleft",pch=16,col=c("red","blue"),legend=c("Série 1","Série 2"),title="Titre de légende")

```

### ggplot2

Il existe trois principaux systèmes dans R pour effectuer des graphiques. Les graphiques de bases sont représentés par les fonctions `plot`, `par` et les fonctions associées. Un autre système, passablement plus compliqué est le package [lattice](https://cran.r-project.org/web/packages/lattice/index.html) qui est souvent utilisé par d'autres fonctions. Un autre système, très populaire, est ggplot2 qui est de plus en plus utilisé. Un des principaux avantages de [ggplot2](http://ggplot2.org/) est que ce système permet de faire rapidement des graphiques plus attrayants comparativement aux graphiques de bases. La documentation concernant ggplot2 est également très détaillée et bien expliquée pour quiconque voudrait employer ce système. Toutefois, dans ce cours, nous n'utiliserons que les graphiques de bases puisque ceux-ci sont plus souvent utilisés par d'autres packages utiles en écologie.


## Exercice

Pour cet exercice, nous utiliserons une base de données ([pines.csv](https://raw.githubusercontent.com/frousseu/ECL749/master/data/pines.csv)) portant sur la croissance de jeunes Pins blancs (*Pinus strobus*) en lien avec avec l'utilisation d'un fertilisant, la déprédation par le Cerf de Virginie, la compétition avec la strate arbustive et l'espacement entre les individus. Cette base de données comporte plusieurs colonnes:

<br>

- **height**: hauteur de l'arbre
- **width**: largeur de l'arbre (maximale avec les branches)
- **height_ini**: hauteur initiale de l'arbre
- **row**: position de l'arbre selon les rangées de la plantation
- **col**: position de l'arbre selon les colonnes de la plantation
- **deer**: présence de broutage par le cerf (0 = non, 1 = oui)
- **fert**: utilisation d'un fertilisant (0 = non, 1 = oui)
- **spacing**: espacement avec les voisins (10 ou 15m) 
- **cover**: recouvrement arbustif (0 = aucun, 1 = un peu, 2 = modéré, 3 = beaucoup)

<br>

Vous devrez réaliser plusieurs tâches et/ou répondre aux questions suivantes:

1) Importez la base de données.

2) Explorez et illustrez les liens entre la hauteur ou la largeur et les différentes variables explicatives (utilisez `boxplot`ainsi que la fonction `par` et son argument `mfrow` pour fractionner votre fenêtre graphique).

3) Effectuez une ANOVA afin d'étudier l'effet du broutement, de la couverture arbustive, du fertilisant ou de l'espacement sur la hauteur ou la largeur des individus. Pour ce faire, vous pouvez utiliser les fonctions `lm` ou `aov` en combinaison avec la fonction `summary`. Interprétez également les résultats.

4) Réalisez une carte schématique permettant d'illustrer la plantation et les traitements (espacement et fertilisant). Pour ce faire, vous devrez utiliser les fonctions `plot`, `legend` et possiblement `points`. Voux aurez également besoin des différents paramètres graphiques (arguments) décrits plus haut (`col`, `cex`, `pch`). La tâche pourrait aussi être facilitée en créant des groupes selon les différentes possibilités.


### Solution

#### 1.

En premier, on importe la base de données. On peut visualiser son contenu avec différentes fonctions comme `head` ou `summary`.
```{r,eval=FALSE}

d<-read.csv("U:/2018/2018/Ateliers/pines.csv",header=TRUE)
head(d)

```

```{r,echo=FALSE}

d<-read.csv("https://raw.githubusercontent.com/frousseu/ECL749/master/data/pines.csv",header=TRUE)
head(d)

```

#### 2.

Par la suite, on explore les liens entre les variables réponses (hauteur et largeur) et les variables explicatives. Pour ce faire, on peut utiliser des `boxplot` et créer une fenêtre graphique avec toutes les variables. On pourrait églement ajouter un titre général à nos graphiques en utilisant le paramètre graphique `oma` pour indiquer que nous voulons une marge externe (*outer margin*) et la fonction `mtext`.

```{r}

par(mfrow=c(2,4),mar=c(4,4,1,1),oma=c(0,0,6,0))

boxplot(height~deer,data=d,xlab="deer",ylab="height")
boxplot(height~fert,data=d,xlab="fert",ylab="height")
boxplot(height~spacing,data=d,xlab="spacing",ylab="height")
boxplot(height~cover,data=d,xlab="cover",ylab="height")
boxplot(width~deer,data=d,xlab="deer",ylab="width")
boxplot(width~fert,data=d,xlab="fert",ylab="width")
boxplot(width~spacing,data=d,xlab="spacing",ylab="width")
boxplot(width~cover,data=d,xlab="cover",ylab="width")

mtext("Effets des traitements sur la hauteur et la largeur des pins",side=3,outer=TRUE,font=2)

```

#### 3.

Pour effectuer une ANOVA, on peut utiliser la commande très générale `lm`. Avant de faire ceci, il faudra toutefois convertir nos variables numériques en facteurs, autrement, `lm` interprétera les différentes variables comme étant des variables numériques. Par exemple, dans la sortie suivante, on peut voir qu'il n'y a qu'une seule ligne par variable et on ne voit pas les niveaux des facteurs (1, 2 ou 3) collés aux noms des variables. Lorsque les étiquettes des niveaux des facteurs n'apparaissent pas à côté des noms des variables, cela indique généralement que les variables sont traitées comme étant numériques.

```{r}

m<-lm(height~deer+fert+spacing+cover,data=d)
summary(m)

```

Avant de faire notre modèle, on doit donc convertir nos variables en facteur en utilisant la fonction `as.factor`. Ce problème ne se poserait pas si nous avions des niveaux représentés par des caractères, puisque la fonction `read.csv` aurait automatiquement convertit ces valeurs en `factor`. Cela n'indique pas qu'il faut nécessairement utiliser des caractères pour désigner des facteurs, mais seulement qu'il faut porter attention aux niveaux identifiés par des entiers, ce qui est relativement commun dans les bases de données.

```{r}

d$deer<-as.factor(d$deer)
d$fert<-as.factor(d$fert)
d$spacing<-as.factor(d$spacing)
d$cover<-as.factor(d$cover)

m<-lm(height~deer+fert+spacing+cover,data=d)
summary(m)

```

On voit maintenant que les noms des coefficients ont changé puisqu'ils se rapportent maintenant aux niveaux des différents facteurs. Maintenant, si on interprète l'effet de nos variables, on voit que le broutement par le cerf à un effet positif sur la taille, mais l'utilisation du fertilisant et l'espacement entre les arbres ont tous deux un effet négatif sur la hauteur des arbres. Quant au recouvrement arbustif, des valeurs faibles ou modérées ont un effet positif comparativement à l'absence de recouvrement arbustif, mais un recouvrement élevé à un effet négatif comparativement à toutes les autres classe de recouvrement. Globablement, on peut aussi dire que nos variables expliquent une portion significative de la variance en hauteur, comme en témoigne le test du *F*. La proportion de variance expliquée (*R*^*2*^) est d'environ 15%. Comment interpréteriez vous ces résultats? Je vous laisse explorer l'effet des variables sur la largeur des arbres.

#### 4.

Pour construire une carte schématique de la plantation en fonction des traitements (fertilisation et espacement), nous pouvons utiliser les numéros de lignes et de colonnes de chacun des arbres. Il y a plusieurs options pour associer des symboles aux traitements. À ce stade, le plus simple est probablement de créer différents sous-ensembles et d'ajouter les points sur un graphique déjà existant. En illustrant la localisation de tous les arbres en premier, on s'assure que la fenêtre graphique couvrira l'ensemble de la plantation. Pour éviter que des points se tracent avec la fonction `plot` initiale, on peut soit utiliser la couleur blanche avec l'argument `col = "white"` ou encore utiliser l'argument `type = "n"`. Ceci produit le graphique, mais sans tracer les points associés. On peut également utiliser la fonction `legend` pour identifier les différentes possibilités. Pour éviter d'écrire des commandes trop longues, j'utilise un vecteur `leg` où j'écris le texte qui composera la légende.

```{r,fig.height=7,fig.width=8}

d1<-d[d$fert==0 & d$spacing==10,]
d2<-d[d$fert==0 & d$spacing==15,]
d3<-d[d$fert==1 & d$spacing==10,]
d4<-d[d$fert==1 & d$spacing==15,]

plot(d$col,d$row,type="n")

points(d1$col,d1$row,col="red",pch=16)
points(d2$col,d2$row,col="blue",pch=16)
points(d3$col,d3$row,col="red",pch=1)
points(d4$col,d4$row,col="blue",pch=1)

leg<-c("fert = 0, spacing = 10","fert = 0, spacing = 15","fert = 1, spacing = 10","fert = 1, spacing = 15")

legend("bottomright",pch=c(16,16,1,1),col=c("red","blue","red","blue"),legend=leg,bty="n",title="Traitements")


```


# Atelier 3

## Retour

### L'argument `sep`

L'argument `sep` permet de spécifier aux fonctionx `read.table` ou `read.csv` quel est le séparateur utilisé dans un fichier *.csv*. Par défaut, `sep = ","` dans la fonction `read.csv`. Si vous spécifiez `sep = ";"`, alors qu'en réalité vos données sont séparées par une virgule, vos données seront lues et considérées comme faisant parti d'une seule colonne. Consultez la page d'aide sur la fonction `?read.table` pour plus de détails.

### Vecteurs vs `data.frame`

Plusieurs ont été tenté de renommer les colonnes et de se créer des vecteurs indépendants pour ensuite les soumettre aux fonctions `boxplot` ou `lm`. Ceci est généralement à éviter. Premièrement, cela implique plus de travail et plus de lignes de codes. Ensuite, en créant des vecteurs indépendants, on court le risque de perdre l'ordre selon lequel les valeurs sont emmagasinées ou d'avoir des vecteurs de longueurs différentes si on décide de supprimer les valeurs manquantes dans certains vecteurs, mais qu'on oublie de le faire dans d'autres. La meilleure façon de procéder est de faire usage de l'argument `data` lorsque celui-ci est disponible et donc d'utiliser notre `data.frame`. De plus, lorsque l'argument `data` est utilié, il devient inutile d'utiliser le `$` pour indiquer nos variables. Par exemple, les deux lignes suivantes sont équivalentes.

```{r, eval=FALSE}
boxplot(d$height~d$deer,data=d)
boxplot(height~deer,data=d)
```

### Les formules

Les formules sont beaucoup utilisées dans R, particulièrement lorsqu'on fait des modèles. Une formule s'écrit généralement de cette façon: ` réponse ~ var1 + var2`. Le symble `~` veut souvent dire "expliqué par" ou "groupé par". Par exemple, le premier argument à la fonction `boxplot` est une formule. Les arguments donnés sous cette forme sont généralement accompagnés d'un argument `data`.

### `boxplot` avec `num ~ num`

Les boxplots sont faits pour étudier les valeurs de variables quantitatives en fonction de variables catégoriques. Si vous faites un boxplot pour deux valeurs numériques, vous obtiendrez une boîte pour chacune des valeurs uniques de la variable "explicative", ce qui n'est pas très utile.

```{r}
boxplot(height~width,data=d)
```

### Transformation en facteurs

La plupart des fonctions servant à faire des modèles vont exiger que les variables catégoriques soient préalablement transformées en facteur. Dans certains cas, les variables caractères seront converties en facteurs par la fonction utilisée. Cependant, si vos facteurs sont représentés par des valeurs numériques, il est impératif de les transformer en facteurs, autrement, ils seront considérés comme des variables numériques et vos analyses seront erronées.

## Mieux comprendre son modèle avec `predict`

La fonction `predict` est utilisée pour générer des prédictions à partir d'un modèle déjà existant. Par exemple, voici comment utiliser cette fonction avec un modèle fictif. Premièrement, créeons un modèle fictif avec une variable explicative numérique (x) et une variable explicative catégorique (sexe).

```{r}

n<-100
x<-runif(n,min=0,max=100)
val<-rep(c(0,100),each=n/2)
sexe<-rep(c("m","f"),each=n/2)
y<-100+2*x+val+rnorm(n,mean=0,sd=20)
d<-data.frame(y,x,sexe)
plot(d$x,d$y,col=ifelse(d$sexe=="m","red","blue"))
```

Voici l'estimation des paramètres du modèle avec la fonction `lm`.

```{r}

m<-lm(y~x+sexe,data=d)
summary(m)

```

Avec `predict`, on soumet des données à notre modèle pour générer des prédictions. Ici, on demande de faire varier x de 0 à 100 et on fixe le facteur sexe à "m". On met ces valeurs dans un `data.frame` qui sera utilisé par `predict` pour générer les prédictions. Ensuite, on traces ces valeurs prédites à l'aide fonction `lines`. 

```{r}

dat<-data.frame(x=0:100,sexe="m")
p<-predict(m,newdata=dat)

plot(d$x,d$y,col=ifelse(d$sexe=="m","red","blue"))
lines(0:100,p,col="red")

```


## Exercices

### Les coûts de la reproduction

Le premier exercice consiste à étudier l'effet de la reproduction sur la longévité chez les mâles de drosophiles (une espèce de mouche). L'idée est que la reproduction a probablement un coût et ce coût pourrait être observé sur la longévité des individus; les mâles étant davantage exposés à la reproduction devraient vivre moins longtemps. Voici la base de données [flies.csv](https://raw.githubusercontent.com/frousseu/ECL749/master/data/flies.csv). Cinq traitements ont été utilisés. Les mâles ont été mis en présence de 0, 1 ou 8 femelles et celles-ci étaient soient vierges, soient gestantes (donc non-réceptives à l'accouplement). D'autres variables ont été mesurées, notamment la longueur du thorax des mâles et la proportion du temps passé à dormir. Dans cet exercice vous devez:

1) Explorez les données, i.e. faire des graphiques permettant d'illustrer la distribution ou les liens entres les différentes variables.

2) Déterminez si la longévité est influencée par le traitement.

3) Vérifiez les conditions d'applications avec la fonction `plot` appliquée sur votre modèle.


#### Solution

On importe d'abord le fichier et on effectue quelques graphiques pour explorer les données.

```{r,fig.width=9,fig.height=3}

d<-read.csv("https://raw.githubusercontent.com/frousseu/ECL749/master/data/flies.csv")
par(mfrow=c(1,3),mar=c(4,4,1,1))
plot(d$Thorax,d$Longevity)
plot(d$Sleep,d$Longevity)
boxplot(Longevity~Treatment,data=d)

```

La longévité semble beaucoup plus faible pour les mâles exposés à plusieurs femelles réceptives. Aussi, la taille du thorax semble avoir un effet positif très fort sur la longévité. Il serait donc important d'inclure cette variable comme contrôle (même si elle n'est pas spécifiquement d'intérêt) afin de réduire le bruit dans nos observations. La proportion du temps passé à dormir ne semble pas avoir d'effet sur la longévité, mais vérifions tout de même ceci en incluant ces variables dans un modèle.

```{r}
m<-lm(Longevity~Treatment+Thorax+Sleep,data=d)
summary(m)
```

On a un effet positif du thorax sur la longévité et un effet du traitement sur la longévité. Les mâles exposés à des femelles réceptives vivent moins longtemps que les mâles moins ou pas exposés et ceci est particulièrement vrai chez les mâles fortement exposés. On pourrait également comparer les traitements entre eux avec un test de comparaison multiple. Puisque nous avons utilisé la fonction `lm` nous ne pouvons pas prendre `TukeyHSD` qui ne fonctionne qu'avec `aov`, mais nous pouvons prendre la fonction plus générale `glht` dans le package [multcomp](https://cran.r-project.org/web/packages/multcomp/index.html).

```{r}
library(multcomp)
summary(glht(m,linfct = mcp(Treatment = "Tukey")))
```

Ce sont surtout les traitements où les mâles ont été mis en présence de femelles réceptives qui ont eu un effet négatif sur la longévité. Du côté des conditions d'applications de la régression, on note une certaine hétéroscédasticité, *i.e.* que la variance change selon les valeurs prédites. Ceci est possiblement un problème, mais nous assumerons que les conditions ne dévient pas trop de l'homoscédasticité. Par contre, on peut voir que les résidus ont une distribution approximativement normale comme en témoigne le *QQ-plot*.

```{r,fig.width=7,fig.height=5}
par(mfrow=c(2,2))
plot(m)
```

Pour mieux illustrer les prédictions de notre modèle, utilisons un graphique à bande avec des intervalles de confiance sur les prédictions. Je vais vous laisser étudier le code. Notez l'utilisation d'une boucle à la fin du code. Ici, *i* prendra toute les valeurs correspondant aux lignes du tableau de prédictions.

```{r,fig.width=7,fig.height=4.5}
# On produit un tableau de valeurs avec lequel on veut générer des prédictions
dat<-data.frame(Treatment=unique(d$Treatment),Thorax=mean(d$Thorax),Sleep=mean(d$Sleep))

# On organise nos valeurs selon un ordre logique
dat<-dat[c(2,3,4,1,5),]

# On prédit nos valeurs avec un intervalle de confiance
p<-predict(m,newdata=dat,interval="confidence")

# On produit un barplot
b<-barplot(p[,1],names.arg=dat$Treatment,col="green4",border=NA,ylim=c(0,max(p)),ylab="Longevity",xlab="Treatment")

# On ajoute les bornes inférieures et supérieurs des intervalles de confiance
for(i in 1:nrow(dat)){
  lines(rep(b[i,1],2),c(p[i,2],p[i,3]))
}
  
```


### Tendances dans la phénologie de nidification

Pour ce deuxième exercice, on veut savoir s'il y a des changements dans les dates de pontes à travers les années chez une espèce d'oiseau (la Paruline jaune). Avec les changements climatiques, on pourrait s'attendre à ce que les oiseaux nichent de plus en plus tôt à chaque saison. Voici la base de données [warblers.csv](https://raw.githubusercontent.com/frousseu/ECL749/master/data/warblers.csv). Est-ce que ces changements sont les mêmes d'une province à l'autre? La colonne *jul* donne le jour julien de la date de ponte du premier oeuf (nb de jour depuis le 1er janvier). Dans cet exercice, vous devez:

1) Explorez les données (i.e., familiarisez-vous avec la base de données).

2) Déterminer s'il y a des changements dans les dates de ponte au cours des dernières années et si ces changements sont différents d'une province à l'autre.

3) Illustrez les prédictions de votre modèle en utilisant la fonction `predict`. Pour ce faire, vous devrez utiliser l'argument `newdata` avec lequel vous soumettrez des observations à votre modèle.

4) Est-ce que les suppositions de base sont respectées? Est-ce que vous voyez des choses à améliorer avec cette analyse?


#### Solution

Chargeons d'abord les données et déterminons d'abord combien il y a d'observations par province et par année.

```{r}
d<-read.csv("https://raw.githubusercontent.com/frousseu/ECL749/master/data/warblers.csv")

table(d$prov)
hist(d$year)

```

Illustrons les données en lien avec notre question.

```{r}
plot(d$year,d$jul,type="n")
points(d$year[d$prov=="ON"],d$jul[d$prov=="ON"],col="darkred")
points(d$year[d$prov=="QC"],d$jul[d$prov=="QC"],col="darkblue")
points(d$year[d$prov=="NB"],d$jul[d$prov=="NB"],col="green4")
legend("topright",pch=1,col=c("darkred","darkblue","green4"),legend=c("ON","QC","NB"),bty="n")

```


Pour déterminer si les changements dans la date de ponte dépendent de la province, il faut utiliser une interaction entre l'année et la province. Pour ce faire, on peut écrire notre modèle de cette façon.

```{r}

m<-lm(jul~year*prov,data=d)
summary(m)

```

On a effectivement une interaction significative entre la province et l'année ce qui nous indique que les changements dans la date de ponte ne sont pas les mêmes d'une province à l'autre. Cependant, pour bien interpréter cette interaction, il est préférable d'utiliser un graphique illustrant les prédictions afin d'éviter la gymnastique difficile du calcul avec les coefficients du modèle.

```{r}

dat<-expand.grid(year=min(d$year):max(d$year),prov=c("ON","QC","NB"))
p<-predict(m,dat)
dat$p<-p

plot(d$year,d$jul,type="n")
points(d$year[d$prov=="ON"],d$jul[d$prov=="ON"],col="darkred")
points(d$year[d$prov=="QC"],d$jul[d$prov=="QC"],col="darkblue")
points(d$year[d$prov=="NB"],d$jul[d$prov=="NB"],col="green4")
legend("topright",pch=1,col=c("darkred","darkblue","green4"),legend=c("ON","QC","NB"),bty="n")

lines(p~year,data=dat[dat$prov=="ON",],col="darkred",lwd=2)
lines(p~year,data=dat[dat$prov=="QC",],col="darkblue",lwd=2)
lines(p~year,data=dat[dat$prov=="NB",],col="green4",lwd=2)

```

Du côté des conditions d'applications, les résidus ne suivent clairement pas une distribution normale. Il n'est toutefois pas évident de déterminer ce qui devrait être fait pour corriger la situation. Une option serait peut être d'utiliser la [régression quantile](https://esajournals.onlinelibrary.wiley.com/doi/10.1890/1540-9295(2003)001[0412%3AAGITQR]2.0.CO%3B2), qui comporte moins de conditions et qui permet d'étudier la réponse à des quantiles spécifiques au lieu de la régression qui permet d'étudier la réponse moyenne. Un autre problème évident est que nous ne prenons pas en compte la possible corrélation temporelle entre les observations. Il faudrait également ajouter des intervalles de confiance à nos courbes de prédictions. 


# Atelier 4

Pour cet atelier, vous apprendrez à utiliser différentes fonctions pour explorer, manipuler et mettre en forme une base données. Cette base de données contient des observations de nombres d'individus pour 3 espèces d'oiseaux (Paruline couronnée (PACO), Carouge à épaulettes (CAEP) et Moineau domestique (MODO)) soumises lors de sorties sur le terrain. À chaque fois qu'un observateur va sur le terrain, un feuillet est soumis où le nombre d'individus de chaque espèce est noté. Nous avons ces informations pour les trois espèces d'oiseaux. Ces feuillets sont rattachés à différentes cellules ayant chacune un identifiant et des coordonnées. Vous devrez également intégrer des données d'habitat associées à chacune de ces cellules. Voici le contenu de ces deux bases de données ainsi que les tâches à accomplir.

<!-- h<-read.csv("https://raw.githubusercontent.com/frousseu/ECL749/master/data/cell_milieux.csv",sep=";") -->
<!-- d<-read.csv("https://raw.githubusercontent.com/frousseu/ECL749/master/data/cell_oiseaux.csv",sep=";") -->

<br>

[**cell_oiseaux**](https://raw.githubusercontent.com/frousseu/ECL749/master/data/cell_oiseaux.csv)

- **cell**: identifiant de la cellule
- **Latitude**: latitude
- **Longitude**: longitude
- **PACO**: nb d'individus pour la Paruline couronnée
- **CAEP**: nb d'individus pour le Carouge à épaulettes
- **MODO**: nb d'individus pour Moineau domestique
- **day**: date
- **month**: mois
- **year**: année

<br>

[**cell_milieux**](https://raw.githubusercontent.com/frousseu/ECL749/master/data/cell_milieux.csv)

- **cell**: identifiant de la cellule
- **%MilieuNaturel**: % de milieus naturels (forêt, milieux humides, etc.)
- **%BatiCommercial**: % de milieux commerciaux
- **%BatiResidentiel**: % de milieux résidentiels
- **%Agricole**: % de milieux agricoles

<br>

1) Importez les bases de données.

2) Créez une colonne nommée "date" avec le format "2019-02-13" en utilisant la fonction `as.Date`. Vous aurez préalablement à assembler vos valeurs pour obtenir le format voulu à l'aide de la fonction `paste` qui permet de coller ensemble des chaînes de caractères. Voici des exemples d'utilisation de ces deux fonctions. 

```{r}

paste(1:5,c("a","b","c","d","e"),sep="_")
x<-as.Date(c("2019-02-12","2019-02-13"))
x
class(x)

```

De façon interne, le format `Date` est stocké comme un entier représentant le nombre de jours depuis 1970-01-01.

```{r}
as.integer(as.Date(c("1970-01-01","1971-01-01")))
```

3) Ordonnez votre tableau de données par date à l'aide de la fonction `order`. Cette fonction permet de réorganiser les lignes en fonction de l'ordre des éléments choisis. Voici un exemple avec le jeu de données `iris` inclus dans R.

```{r,results="hold"}

x<-iris[order(iris$Species,iris$Petal.Length),]
head(x,5)
tail(x,5)

```

4) Par erreur, des valeurs de NA ont été utilisées dans certains cas lorsque le nombre d'individus rencontrés était de 0. Remplacez ces valeurs de `NA` par des 0 dans les nombres d'individus. Ici, vous aurez besoin des fonctions `ifelse` et `is.na`.

Par exemple, voici une utilisation de ces deux fonctions.

```{r}

v<-c(1,2,3,NA)
is.na(v)
v<-ifelse(is.na(v),0,v)
v

```

5) Illustrez pour une espèce donnée le nb d'individus vu à chaque jour. Pour ce faire, vous devrez utiliser votre date comme l'élément variant selon l'axe des X (sous le format `Date`). La date sera convertie en valeur numérique et les étiquettes s'ajusteront au format `Date`.

6) Illustrez la localisation des différentes cellules dans un graphique. Vous remarquerez que les coordonnées contiennent des virgules au lieu des points. Il vous faudra donc transformer ces virgules en points avec la fonction `gsub` et ensuite transformer ce dernier résultat en valeur numérique avec la fonction `as.numeric`. Voici un exemple d'utilisation de la fonction `gsub`. Cette fonction permet de remplacer un caractère par un autre dans un vecteur de caractères.

```{r}

x<-c("45,67","45,98")
y<-gsub(",",".",x)
y
y<-as.numeric(y)
y

```

Puisqu'il y a plusieurs lignes de données pour chaque cellule, il serait préférable de ne conserver qu'une seule ligne par cellule pour illustrer la localisation de chaque cellule afin d'éviter de tracer trop de points inutilement. Pour ne conserver qu'une seule ligne par cellule, vous pouvez utiliser la fonction `unique` qui permet de conserver les valeurs qui ne sont pas des doublons. Voici un exemple d'utilisation de la fonction `unique` appliquée sur un vecteur et sur un `data.frame`. Avec cette fonction, vous pourriez vous créer un `data.frame` ne contenant que les coordonnées des différentes cellules.


```{r}

x<-c("a","a","a","b","b","c")
unique(x)
y<-c(1,2,1,3,3,3)
d<-data.frame(x,y)
d
unique(d)

```


7) À l'aide de vos coordonées, illustrez les abondances soumises d'une de vos espèces d'oiseaux en faisant varier la taille de vos points.

8) Pour chaque espèce, quelle est la proportion de feuillets contenant au moins un individu? 

9) Votre graphique précédent illustre chacune des mentions ce qui peut rendre difficile l'appréciation de l'abondance de l'espèce à travers les différentes régions. Afin de résumer cette information par cellule, calculez le nombre moyen d'individus mentionnés par cellule et illustrez plutôt ces valeurs. Il y a plusieurs façons de faire ce calcul dans R. La façon de base est probablement d'employer la fonction `aggregate` avec sa version utilisant les formules. Voici un exemple d'utilisation de cette fonction avec le jeu de données `iris`.

```{r}

head(iris)
aggregate(Petal.Length~Species,data=iris,FUN=mean)
aggregate(.~Species,data=iris,FUN=mean)

```

10) Quel est le nombre moyen de Parulines couronnées mentionné par feuillet à chaque mois? Illustrez ces valeurs à l'aide de la fonction `barplot`.

11) Des données de types de milieux ont été extraites pour chaque cellule, mais ces données se trouvent dans une autre base de données. Ajoutez ces données de types de milieux à vos données d'observations. Pour ce faire, vous devrez utiliser la fonction `merge`. Au préalable, changez les noms de colonnes des types de milieux pour éliminer les "%" qui risqueraient de causer des difficultés lors de la création d'éventuels modèles. Pour ce faire, vous pouvez utiliser la fonction `names`  avec l'indexage et la fonction `which`. En voici un exemple. La fonction `which` identifie les positions dans le vecteur où une ou des conditions sont rencontrées.

```{r}

x<-iris
head(x)
names(x)
w<-which(names(x)=="Species") 
w
names(x)[w]<-"espèces"
head(x)

```

12) Ajoutez un nouveau type de milieu (urbain) en additionnant les superficies occupées par les milieux résidentiels et les milieux commerciaux.

13) Illustrez dans une même fenêtre graphique les valeurs de % de types de milieux pour chaque type. Cela correspond à la création de 4 cartes pour illustrer chaque type de milieu.

### Solution

1)

```{r}

o<-read.csv("https://raw.githubusercontent.com/frousseu/ECL749/master/data/cell_oiseaux.csv",sep=";",header=TRUE)
h<-read.csv("https://raw.githubusercontent.com/frousseu/ECL749/master/data/cell_milieux.csv",sep=";",header=TRUE)

```

2)

```{r}

o$date<-as.Date(paste(o$year,o$month,o$day,sep="-"))

```


3)

```{r}

o<-o[order(o$date),]

```

4)

Vous pouvez vérifier s'il y a des `NA` dans les différentes colonnes avec la fonction `summary` ou en utilisant `table(is.na(d$PACO))` pour une colonne en particulier. Il semble y avoir des `NA` uniquement dans la colonne `PACO`.

```{r}
o$PACO<-ifelse(is.na(o$PACO),0,o$PACO)

```

5)

Ce graphique nous permet de voir qu'il y a qqch qui cloche avec les abondances de CAEP et PACO... En bonus, je rajoute sur l'axe des X du dernier graphique un peu plus de précision
```{r, fig.height=7,fig.width=9}

par(mfrow=c(3,1))
plot(o$date,o$PACO)
plot(o$date,o$CAEP)
plot(o$date,o$MODO,xaxt="n")
x<-seq.Date(as.Date("2005-01-01"),as.Date("2011-01-01"),by="2 month")
axis.Date(side=1,x,at=x,format="%Y-%b",las=2)

```

6)

```{r}

o$Longitude<-as.numeric(gsub(",",".",o$Longitude))
o$Latitude<-as.numeric(gsub(",",".",o$Latitude))

cells<-unique(o[,c("cell","Longitude","Latitude")])
            
par(mfrow=c(1,1))  
plot(cells$Longitude,cells$Latitude)

```

7)

Pour ce faire, le plus simple est d'utiliser l'argument `cex` de la fonction `plot` avec les abondances d'oiseaux transformées ou divisées par une certaine valeurs. Ces valeurs indiqueront la surface occupée par chaque point et par défaut, cette surface est de 1. Il faut donc réduire certaines valeurs pour éviter d'avoir des points trop grands. Une transformation `log` permettrait d'écraser les valeurs très grandes. Vous pourriez aussi divisier vos valeurs par un facteur approprié. Il est également possible d'utiliser des points pleins avec l'argument `pch` et la fonction `gray` avec laquelle on peu spécifier un gris plus ou moins transparent. 

```{r, fig.height=7,fig.width=9}

par(mfrow=c(2,2))
plot(o$Longitude,o$Latitude,cex=log(o$PACO),pch=16,col=gray(level=0,alpha=0.1))
plot(o$Longitude,o$Latitude,cex=log(o$CAEP),pch=16,col=gray(level=0,alpha=0.1))
plot(o$Longitude,o$Latitude,cex=log(o$MODO),pch=16,col=gray(level=0,alpha=0.1))

```

8)

Pour obtenir ceci, il n'y a qu'à utiliser `table` sur chaque colonne d'abondance pour calculer le nombre de fois où les valeurs sont supérieures ou inférieures à 0 et ensuite faire les calculs "à la mitaine" ou avec R.

```{r}

table(o$PACO>0)

```

Une autre façon encore plus efficace serait de convertir les colonnes d'espèces en matrice et d'additionner le nombre de valeurs répondant à notre critère. Les `TRUE` seront convertis en 1 et les `FALSE` en 0 lors de l'addition des colonnes.

```{r}

m<-as.matrix(o[,c("PACO","CAEP","MODO")])
colSums(m>0)/nrow(o)

```

9)

La façon la plus efficace ici est probablement de tout calculer d'un coup en utilisant le `.` dans une formule et de regrouper ces valeurs par coordonnées et par cellules. Par la suite on peut utiliser les mêmes graphiques que ceux utilisés précédemment. Les abondances seront toutefois beaucoup moins extrêmes et une autre transformation des valeurs seraient pertinentes, par exemple une transformation racine-carrée (`sqrt`).

```{r, fig.height=7,fig.width=9}

v<-aggregate(.~cell+Longitude+Latitude,data=o[,c("cell","Longitude","Latitude","PACO","CAEP","MODO")],FUN=mean)

par(mfrow=c(2,2))
plot(v$Longitude,v$Latitude,cex=sqrt(v$PACO),pch=16,col=gray(level=0,alpha=0.1))
plot(v$Longitude,v$Latitude,cex=sqrt(v$CAEP),pch=16,col=gray(level=0,alpha=0.1))
plot(v$Longitude,v$Latitude,cex=sqrt(v$MODO),pch=16,col=gray(level=0,alpha=0.1))

```


10)

Pour ce faire, on peut utiliser un `aggregate` approprié. On voit que cette espèce est surtout présente du mois de mai au mois de septembre.

```{r}

v<-aggregate(PACO~month,data=o,mean)

par(mfrow=c(1,1))
barplot(v$PACO,names.arg=v$month,ylab="Nb moyen de PACO",xlab="Mois")

```


11)

Dans mon cas, les "%" ont été transformés en "X.". Il faut donc utiliser ces mêmes noms. Le code suivant peut se traduire comme voulant dire "trouve la position de ce nom et change le nom en cette position par cet autre nom". 

```{r}

names(h)[which(names(h)=="X.MilieuNaturel")]<-"naturel"
names(h)[which(names(h)=="X.Agricole")]<-"agricole"
names(h)[which(names(h)=="X.BatiResidentiel")]<-"residentiel"
names(h)[which(names(h)=="X.BatiCommercial")]<-"commercial"

```

Une autre façon de faire pourrait être de remplacer tous les "X." par qqch d'autres (dans notre cas, par rien)

```{r,eval=FALSE}

names(h)<-gsub("X.","",names(h))

```

Par la suite, on utilise `merge` pour ajouter les données d'habitats aux données d'abondances.

```{r}

o<-merge(o,h)
head(o)

```

12)

```{r}

o$urbain<-o$residentiel+o$commercial

```

13)

Encore une fois, ici on pourrait éviter de tracer beaucoup de points en ne prenant que les valeurs uniques pour chaque cellule. Pour ce faire, on pourrait aussi fusionner les données d'habitats avec l'objets `cells` crée plus haut.

```{r, fig.height=7,fig.width=9}

cells<-merge(cells,h)

par(mfrow=c(2,2))
plot(cells$Longitude,cells$Latitude,cex=3*cells$naturel/100,pch=16)
plot(cells$Longitude,cells$Latitude,cex=3*cells$agricole/100,pch=16)
plot(cells$Longitude,cells$Latitude,cex=2*cells$residentiel/100,pch=16)
plot(cells$Longitude,cells$Latitude,cex=2*cells$commercial/100,pch=16)

```

Si vous voulez visualiser où se trouvent ces cellules, vous pouvez le faire en faisant appel à deux packages, soit **sp** et **mapview**. Voici comment faire.

```{r,out.width="100%"}

library(sp)
library(mapview)

coordinates(cells)<- ~ Longitude + Latitude # on indique quelles sont les coordonnées
proj4string(cells)<-"+init=epsg:4326" # on spécifie le type de projection utilisé (WGS84 en lat/lon)

mapview(cells) # on trace les points avec différents fond de carte et on ouvre dans le navigateur

```

# Atelier 5

<!-- data is frogs from the DAAG package -->

Pour cet atelier, nous nous intéresserons aux variables affectant la présence d'une espèce de grenouilles ([Southern Corroboree frog](https://en.wikipedia.org/wiki/Corroboree_frog)) retrouvée en Australie. Pour ce faire, nous avons une base de données [frogs.csv](https://raw.githubusercontent.com/frousseu/ECL749/master/data/frogs.csv) avec différentes variables explicatives. Pour cet exercice, vous devrez déterminer quelles sont les variables pertinentes à utiliser pour comprendre ou prédire l'occurrence de l'espèce et vous devrez illustrer les prédictions de votre modèle à l'aide de la fonction `predict` et de graphiques ou encore en utilisant les packages [**visreg**](http://pbreheny.github.io/visreg/) ou [**ggeffects**](https://strengejacke.github.io/ggeffects/articles/introduction_plotmethod.html). Pour mieux comprendre l'utilisation de ces packages, le plus simple est de se référer à leur page web. N'oubliez pas de faire un peu d'explorations de données et de vous poser quelques questions avant de sélectionner vos variables explicatives. 

<br>

- **pres.abs**: 0 = espèce absente, 1 = espèce présente
- **northing**: coordoonées nord
- **easting**: coordonnées est
- **altitude**: altitude en mètres
- **distance**: distance à la population ou à la mention de présence connue la plus près
- **NoOfPools**: nombre de mares de reproduction potentielles dans le secteur immédiat (dans un certain rayon)
- **avrain**: quantité de pluie moyenne pendant le printemps
- **meanmin**: température moyenne minimale pendant le printemps
- **meanmax**: température moyenne maximale pendant le printemps

<br>

1) Étudiez la distribution de vos variables avec la fonction `hist` et les relations entre vos variables avec la fonction `plot` ou autres.

2) Illustrez les présences/absences dans l'espace avec les coordonnées *easting* et *northing*.

3) Construisez et interprétez votre modèle permettant d'expliquer la présence de l'espèce.

4) Utilisez la fonction `predict` ou les packages [**visreg**](https://pbreheny.github.io/visreg/) ou [**ggeffects**](https://strengejacke.github.io/ggeffects/articles/introduction_plotmethod.html) pour illustrer les prédictions de votre modèle. Ces deux packages devraient vous faciliter la tâche comparativement à l'utilisation de `predict`.


## Solution

La première étape consiste à explorer les différentes valeurs de nos variables. On peut faire cela avec la fonction `summary`. 

```{r}

d<-read.csv("https://raw.githubusercontent.com/frousseu/ECL749/master/data/frogs.csv",sep=";")
summary(d)

```

Par la suite, il serait préférable d'inspecter les liens entre les différentes variables explicatives potentielles. On peut s'attendre à ce que certaines soient fortement corrélées (*i.e.* **meanmin** et **meanmax**). Pour illustrer toutes les paires de variables, on peut utiliser les fonctions `plot` ou `pairs` appliquées à notre jeu de données. On peut également éliminer la variable réponse et les coordonnées puisque celles-ci ne feront pas partie de nos variables explicatives. Ces trois variables se trouvent dans les 3 premières colonnes de notre tableau et on peut les éliminer en utilisant l'indexage négatif. Les coordonnées pourraient également être utilisées dans notre modèle, mais cela impliquerait que nous pensons qu'il devrait y avoir des gradients (linéaires) de probabilité de présence est-ouest ou nord-sud.

```{r,fig.width=8,fig.height=7}

plot(d[,-(1:3)])

```

À première vue, on a une corrélation très forte entre certaines variables, notamment entre l'altitude et les températures minimales et maximales. Il serait donc préférable de choisir l'une ou l'autre de ces variables pour éviter la collinéarité et la redondance dans notre modèle. On pourrait également utiliser la fonction `cor` pour calculer la corrélation entre chacune de nos paires de variables. 

```{r}

cor(d[,-(1:3)])

```

On a également une corrélation importante entre la pluie et l'altitude et la température maximale. Encore une fois, il pourrait être important de choisir l'une ou l'autre de ces variables. Bien que la température est certainement très importante pour les amphibiens, l'altitude est selon moi plus utile comme variable si l'intention est de faire de la prédiction sur la présence de l'espèce. En effet, cette variable est probablement plus facilement accessible à l'échelle du paysage comparativement à la température. 

Maintenant, on peut également se poser la question quelle est la relation entre les variables explicatives et la probabilité de présence? Pour ce faire, on peut encore une fois utiliser la fonction plot avec une formule. L'utilisation du point `.` indique que nous voulons considérer toutes les variables du tableau de données.

```{r,fig.width=8,fig.height=6}
par(mfrow=c(2,3))
plot(pres.abs~.,data=d[,-(2:3)])

```

Ce n'est pas si évident sur les graphiques en raison des valeurs binaires, mais il semble parfois y avoir des probabilité de présence plus élevées pour des valeurs intermédiaires de nos différentes variables environnementales. Si on y réfléchit un peu, ceci n'est pas nécessairement surprenant. Imaginons une espèce fictive ayant une aire de distribution donnée et une variable climatique comme la température moyenne annuelle. Il y aura probablement une température minimale en dessous de laquelle l'espèce ne sera jamais présente ainsi qu'une température maximale au delà de laquelle l'espèce ne sera jamais rencontrée. Si on fait des inventaires à grande échelle pour trouver cette espèce, on obtiendra probablement que l'espèce est davantage rencontrée pour des valeurs intermédiaires de température moyenne annuelle. Il est possible qu'on trouve une relation linéaire positive ou négative entre la température et la présence de l'espèce, mais si on couvre un gradient de température assez étendu, on obtiendra nécessairement que l'espèce est moins abondante ou absente pour les valeurs extrêmes de température de la superficie inventoriée. Dans notre cas, il se pourrait que notre espèce de grenouille se retrouve davantage à des altitudes intermédiaires ce qui pourrait donner lieu à une relation quadratique. Il pourrait donc être judicieux d'inclure des relations quadratiques dans notre modèle. 

A *priori*, il ne me semble pas y avoir d'interactions évidentes à inclure dans le modèle. Puisque les variables climatiques sont très fortement corrélées, je ne sélectionnerais que l'altitude. Les deux autres variables me semblent toutes deux pertinentes à inclure. On s'attend à ce que le nombre de mares *NoOfPools* influence positivement la probabilité de présence. Pour ce qui est de la distance, on s'attend à la même relation. En effet, il est raisonnable de penser que plus on est près d'une présence connue, plus on risque de rencontrer l'espèce. L'effet de cette variable est plus à considérer comme étant un indicateur des conditions locales que comme une variable influençant directement la présence de l'espèce. Par exemple, on a de l'information partielle sur la présence de l'espèce dans une région donnée où on veut raffiner nos connaissances de distribution de l'espèce. Elle pourrait également être liée au potentiel de dispersion de l'espèce dans un context de méta-population.  Un modèle potentiel serait celui-ci:


```{r}

m<-glm(pres.abs~NoOfPools+distance+altitude+I(altitude^2),family="binomial",data=d)
summary(m)

```

On peut voir que l'abondance de mares influence positivement la présence de l'espèce, alors que la distance à une présence connue a un effet négatif sur la probabilité de présence de l'espèce. Du côté de l'altitude, il est très difficile de décrire quel est l'effet sur la probabilité de présence sans utiliser de graphiques. On peut toutefois dire que l'effet quadratique semble justifié comme en témoigne la valeur du coefficient du terme quadratique qui est significativement différent de 0. Remarquez l'utilisation de la fonction `I` qui facilite la formulation du modèle et qui permet d'indiquer de la variable altitude est à la base des deux termes (linéaires et quadratiques). Cela peut nous éviter d'avoir à calculer plus de valeurs lorsque nous utiliserons la fonction `predict`. 

Visualisons cet effet avec la fonction `predict`. En premier, on crée un `data.frame` avec des valeurs que nous allons soumettre à notre modèle. Pour ce faire, on couvre l'étendue de nos valeurs d'altitude et on fixe les autres variables à leur valeur moyenne.

```{r,fig.width=8,fig.height=6}

# on fait varier l'altitude de la valeur min à la valeur max par bond de 10
alt<-seq(min(d$altitude),max(d$altitude),by=10) 

# on crée un newdata avec les autres variables fixées à leur valeur moyenne
dat<-data.frame(altitude=alt,NoOfPools=mean(d$NoOfPools),distance=mean(d$distance)) 

# on sort les prédictions du modèle en précisant que nous les voulons sous l'échelle de notre réponse
p<-predict(m,newdata=dat,type="response")

# on illustre les résultats
plot(d$altitude,d$pres.abs)
lines(alt,p)

```

La probabilité de présence semble atteindre un pic aux alentours de 1400m. Il faut toutefois rester prudent dans l'interprétation précise de ces valeurs, car nous n'avons pas d'intervalles de confiance autour de ces courbes. On pourrait les ajouter en utilisant l'argument `se.fit` de `predict`, mais cela demanderait un peu plus de travail. Nous n'avons d'ailleurs pas encore visualisé l'effet de nos autres variables. Il faudrait produire ces graphiques pour chacune des variables. Il serait possible d'optimiser cette tâche en généralisant le code de prédictions, mais pour l'instant ceci donnerait un code un peu plus difficile à suivre. 


Pour faciliter la visualisation des résultats, nous pouvons faire appel au package *visreg* qui s'occupe de la majeure partie du travail. Les deux premières pages vous indiquent de façon assez simple comment créer des graphiques de visualisation d'un modèle linéaire et même comment visualiser une interaction! Le package a même un [site web](http://pbreheny.github.io/visreg/index.html) pour décrire les fonctionnalités. Il y a notamment une section sur les [GLM](http://pbreheny.github.io/visreg/glm.html). Pour ce package, l'argument qui permet de spécifier que l'on veut notre prédiction sous l'échelle de la réponse s'appelle `scale` contrairement à `type` pour la fonction `predict`.

```{r,fig.width=8,fig.height=6}
library(visreg)

par(mfrow=c(2,2),mar=c(4,3,1,1))
visreg(m,scale="response",ylim=0:1)

```

Certains ont utilisé les coordonnées comme variables explicatives dans leur modèle. Ceci n'est pas nécessairement mauvais, mais cela mérite une bonne réflexion. Est-ce que la relation entre la présence et les coordonnées est linéaire ou est-elle plus complexe? Est-ce que la relation entre les coordonnées et la probabilité de présence pourrait servir à prédire la présence de l'espèce dans d'autres régions? Probablement pas. Si le but est de prédire la présence de l'espèce seulement à l'intérieur de la zone étudiée, les coordonnées pourraient être utilisées. Cependant, il faudrait s'assurer que la relation est linéaire, ce qui serait assez suprenant. Si c'est le cas, il faudrait plutôt se demander s'il n'y a pas une ou des variables non prises en compte qui pourraient créer un tel gradient de probabilité de présence dans l'aire d'étude. Si on s'intéresse à comprendre l'influence des variables environnementales sur l'occurence des grenouilles à l'extérieur de la zone étudiée, la relation observée avec les coordonnées devient probablement inutile. 

Malheureusement, ou plutôt heureusement, il n'y a pas nécessairement une meilleure ou une unique réponse à ce défi d'analyse de données. La mienne n'est qu'une suggestion et vous avez peut être de meilleures suggestions. L'important est de justifier nos choix et de prendre en considération les éléments les plus importants. Un élément important que j'ai ignoré est la potentielle corrélation spatiale entre les observations. Par exemple, est-ce que les observations près les unes des autres peuvent être considérées comme étant indépendantes? Aussi, est-ce qu'il y aurait d'autres variables à prendre en compte dans cette analyse? Comment les inventaires ont été réalisés? Est-ce qu'il faudrait tenir compte de la probabilité de détection de l'espèce? 


# Atelier 6

## Les parasites chez le Colibri à gorge rubis

Pour cet exercice, vous étudierez ce qui influence la charge parasitaire chez le Colibri à gorge rubis (*Archilochus colubris*), une espèce retrouvée au Québec. Dans la base de données [colibris.csv](https://raw.githubusercontent.com/frousseu/ECL749/master/data/colibris.csv), vous retrouverez différentes variables comme le sexe (4 = mâle, 5 = femelle) et l'âge (1 = adulte, 2 = jeune). L'exercice consiste à déterminer quelles sont les variables qui affectent la quantité de parasites. Pour interpréter vos résultats, illustrez graphiquement votre modèle. Obtenez-vous des conclusions semblables si vous faites l'analyse en présence/absence? Pour transformer les valeurs en présence/absence, vous pouvez utiliser la fonction `ifelse`.

<!--

### Solution

On importe d'abord les données et on affiche notre `data.frame` et un petit résumé de ce qu'il contient.
```{r}

d <- read.csv("https://raw.githubusercontent.com/frousseu/ECL749/master/data/colibris.csv")
head(d)
summary(d)

```

On voit quelques zéros dans la colonne *parasites* et on peut donc se demander à quel type de données nous avons à faire. On peut illustrer les valeurs de *parasites* avec un histogramme.
```{r}

hist(d$parasites)

```

On a ici un nombre d'individus, avec des valeurs allant de 0 à environ 40. Il faudra donc probablement modéliser l'abondance de parasites avec une distribution de Poisson. On a également plusieurs colibris dans la base de données. Une deuxième question à se poser est est-ce qu'on a plusieurs comptes de parasites pour un même individus? On peut vérifier ceci en utilisant la fonction `table` qui va comptabiliser le nombre de fois que chaque numéro de bague apparaît dans la base de données. En utilisant une seconde fois la fonction `table`, on compte le nombre de fois où chacune de ces valeurs est observée.

```{r}

table(table(d$bague))

```

On voit que pour la majorité des colibris, on a une seule valeur, mais certains ont plusieurs valeurs (2, 3 ou 4 observations). On devrait donc par défaut se diriger vers les modèles mixtes pour traiter l'individu comme un effet aléatoire puisque les comptes de parasites sur un même individu ne sont pas indépendants. Par contre, puisque la majorité des individus ont une seule observation, cela peut créer des problèmes dans le cadre des modèles mixtes et on pourrait plutôt opter pour effectuer une moyenne ou pour une sélection aléatoire d'une seule observation pour les individus ayant plusieurs observations. On pourrait également comparer les deux approches et déterminer si nos conclusions par rapport à l'effet de nos variables sont fortement affectées par notre méthode d'analyse. Si ce n'est pas le cas, on peut choisir la méthode qui nous convient en justifiant notre choix et en exposant le fait que nos conclusions ne sont pas affectées par la méthode choisie.

On devrait également explorer les liens entre nos variables explicatives. On peut faire ceci avec des `boxplot` ou des graphiques standards.

```{r}

par(mfrow=c(1,2))
boxplot(masse~age,data=d)
boxplot(masse~sexe,data=d)
table(d$sexe,d$age)

```

Les femelles sont plus massives que les mâles et les adultes semblent également plus massifs que les jeunes. Cependant, il semble y avoir une disproportion de mâles par rapport aux femelles chez les jeunes.

Avant de lancer nos modèles, il faut transformer le sexe et l'âge en facteur étant donné que ces deux variables sont représentées par des valeurs numériques.

```{r}

d$sexe<-as.factor(d$sexe)
d$age<-as.factor(d$age)

library(lme4)

m1<-glm(parasites~sexe+age+masse,data=d,family=poisson)
m2<-glmer(parasites~sexe+age+masse+(1|bague),data=d,family=poisson)

summary(m1)
summary(m2)

```

On obtient des résultats bien différents selon nos deux modèles. On a un effet négatif de la masse, mais pour l'âge et le sexe nos conclusions sont très différentes. Puisque nous avons une seule observation pour la majorité des individus, il est peut être préférable de ne pas utiliser de modèles mixtes qui requièrent plusieurs observations pour chaque niveau. 

On peut visualiser les prédictions de nos modèles avec visreg et en créant une fenêtre graphique avec en haut les prédictions pour le glm et en bas les prédictions pour le modèle mixte. Remarquez que nous n'avons pas d'intervalles de confiance autour des prédictions pour le modèle mixte. La raison de ceci est expliquée dans la [GLMM FAQ](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-hypotheses).

```{r,eval=FALSE,echo=FALSE,include=FALSE}

par(mfrow=c(2,3))
visreg(m1,scale="response",ylim=c(0,8))
visreg(m2,"sexe",scale="response",ylim=c(0,8))
visreg(m2,"age",scale="response",ylim=c(0,8))
visreg(m2,"masse",scale="response",ylim=c(0,8))

```

On pourrait opter pour un GLM et ne prendre qu'une seule observation aléatoirement par individu. On peut faire ceci en utilisant une combinaison de `split`, `lapply` et `sample`. Je vous laisse étudier le code en vous donnant quelques indications sur chaque étape.

```{r}

s<-split(d,d$bague) # on sépare les données par individu dans une liste
l<-lapply(s,function(i){ # on applique une fonction sur chaque data.frame de la liste
   if(nrow(i)==1){ # on prend la ligne s'il n'y en qu'une
     i
   }else{
     i[sample(1:nrow(i),1),] # ou on choisit aléatoirement une ligne s'il y en a plusieurs
   } 
})
d2<-do.call("rbind",l) # on fusionne les différents subsets de la liste ensemble dans un nouveau data.frame

```

Dans l'objet `d2`, on a maintenant une seule ligne par individu.

```{r}

m1sub<-glm(parasites~sexe+age+masse,data=d2,family=poisson)
summary(m1sub)

```

Nos conclusions pour ce glm modifié sont très similaires. On conclut donc que les mâles et les jeunes sont davantage infectés par les parasites. Plusieurs interprétations sont possibles, mais aucune ne me semble évidente et il faudrait chercher dans la littérature pour valider ces interprétations. Quant à la masse, elle a un effet négatif sur le nombre de parasites. Ceci pourrait s'expliquer par le fait que les individus plus massifs sont aussi en meilleure santé et donc plus aptes à se défendre contre les parasites.

```{r}

par(mfrow=c(2,2))
visreg(m1sub,scale="response",ylim=c(0,8))

```

-->

## La richesse spécifique le long du littoral

Ici, on s'intéresse aux variables influençant le nb d'espèces rencontrées le long du littoral. On a la hauteur de la station d'échantillonnage par rapport à la hauteur moyenne de la marée ainsi que l'exposition qui est quantifiée à l'aide d'un index construit à partir de la "sévérité" des conditions de la station (force des vagues, longueur de la zone d'impact, pente, substrat allant de fin à grossier). La base de données se trouve à cet endroit [plages.csv](https://raw.githubusercontent.com/frousseu/ECL749/master/data/plages.csv). Une autre base de données [plage_type.csv](https://raw.githubusercontent.com/frousseu/ECL749/master/data/plage_type.csv) est également disponible où le type de plage (roches ou sable) est donnée. Vous devrez fusionner ces deux bases de données pour mettre l'information dans une même base de données. Pour ce faire, vous devrez utiliser la fonction `merge`. Illustrez les résultats de votre modèle. 

<!--

### Solution

Importons d'abord les données.
```{r}

d <- read.csv("https://raw.githubusercontent.com/frousseu/ECL749/master/data/plages.csv")
head(d)

set.seed(123)
s<-sample(c("roches","sable"),9,replace=TRUE)
x<-data.frame(Plage=1:9,Type=s)
write.csv(x,"plage_type.csv",row.names=FALSE)

merge(d,x,by.x="plage",by.y="Plage")

```

Comme pour l'exercice précédent, on a une variable réponse qui correspond à un compte et qui est très asymmétrique à droite avec des valeurs de zéros.
```{r}


hist(d$richesse)
range(d$richesse)

```

On semble également avoir des comptes effectués sur plusieurs plages. Vérifions ceci.

```{r}

table(d$plage)

```

On a cinq observations par plages et 9 plages. Il faudrait donc utiliser des modèles mixtes avec la plage en effet aléatoire. On devrait également explorer les liens entre les différentes variables. On peut inclure à la fois la richesse et les variables explicatives ce qui nous permettra d'un seul coup de vérifier la linéarité du lien avec les variables explicatives et la corrélation des variables explicatives. 

```{r}

plot(d[,c("richesse","exposition","hauteur")])

```

On remarque premièrement qu'il n'y a que trois valeurs d'exposition. On pourrait décider de traiter cette variable comme un facteur, mais puisque l'effet semble linéaire et qu'on peut s'imaginer que les valeurs représentent un gradient on pourrait décider de les traiter comme une variable numérique.

```{r}

m<-glmer(richesse~hauteur+exposition+(1|plage),data=d,family=poisson)
summary(m)

```

On a des effets négatifs significatifs des deux variables ce qui signifie que la hauteur et l'exposition sont toutes deux associées à un moins grand nombre d'espèces. On peut visualiser l'effet de ces deux variables avec `visreg`. 

```{r}

par(mfrow=c(2,3))
visreg(m,scale="linear")
visreg(m,scale="response")

```

La série du haut représente les prédictions du modèle sous l'échelle de la fonction de lien *log* et la série du bas représente les prédictions du modèle à l'échelle de la réponse. Contrairement aux GLMS, il n'y a pas d'intervalles de confiance puisque la meilleure façon de les calculer est incertaine. Ceci est expliqué dans la [GLMM FAQ](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-hypotheses). 

-->

<!--

# Atelier 7

Pour cet exercice, nous allons développer la débrouillardise sur les internets. Nous allons utiliser le jeu de données [iris](https://raw.githubusercontent.com/frousseu/ECL749/master/data/iris.csv) pour effectuer différentes tâches. Cette base de données contient des mesures morphométriques pour trois espèces d'iris.

1. Ordonnez la base de données selon l'espèce et puis selon la longueur des pétales.

2. Trouvez une fonction permettant de faire du *clustering* et tentez d'effectuer un groupement permettant de classifier les individus sur la base de leurs caractéristiques morphologiques. Est-ce que vous êtes capable d'identifier les trois espèces dans les groupes établis?

3. Effectuez une analyse en composantes principales afin de représenter la variation dans ce jeu de données et illustrez les résultats dans un graphique. Pour ce faire, vous pouvez utiliser la fonction `rda` du package **vegan** et les fonctions `plot` ou `ordiplot`. Vous pouvez également vous inspirer de ce blog [https://www.fromthebottomoftheheap.net/2012/04/11/customising-vegans-ordination-plots/](https://www.fromthebottomoftheheap.net/2012/04/11/customising-vegans-ordination-plots/).


### Solution

#### 1.

On charge en premier les données.
```{r}

d <- read.csv("https://raw.githubusercontent.com/frousseu/ECL749/master/data/iris.csv")
head(d)

```


Pour un `data.frame`, `order` permet de trier en fonction de plusieurs colonnes successives. Il s'agit par la suite d'utiliser le résultat en indexant les lignes de notre `data.frame`.
```{r}

d<-d[order(d$Species,d$Petal.Length),]
head(d)

```

Remarquez que si nous avions utilisé la fonction `attach`, l'ordre des éléments dans notre nouveau tableau de données ne serait plus le même que dans les colonnes qui auraient été attachées précédemment. C'est une des raisons pour laquelle l'utilisation de `attach` est déconseillée. 

#### 2.

Ce qu'on veut ici, c'est une méthode qui nous permet de classifier les individus sur la base de leurs caractéristiques morphologiques. Sommes-nous capable de retrouver les espèces en les classifiant avec une quelconque méthode? 

Pour trouver une méthode de classification, la façon la plus simple est de taper *clustering in R* dans *Google*. Le premier lien est le site [Quick-R](https://www.statmethods.net/advstats/cluster.html) de *DataCamp*.  On y trouve entre autres les fonctions `kmeans` et `hclust`. Testons la première. Le code est un peu compliqué puisque l'exemple cherche à identifier plusieurs groupes de façon successive. L'important dans ces exemples est la fonction `kmeans`. Pour son utilisation, on peut aller voir dans le fichier d'aide et dans ses exemples. Les deux arguments importants sont le tableau de variables morphologiques et le nombre de *clusters* désirés.

```{r, echo=FALSE}

set.seed(123)

```

```{r}

k<-kmeans(d[,-5],center=3)
k

```

Si vous étudiez le fichier d'aide (et les exemples) pour voir quelles valeurs sont retournées pas la fonction, vous verrez que les *clusters* sont retournés dans l'objet et qu'ils sont accessibles avec l'opérateur `$`. On peut donc les extraire et les comparer les *clusters* identifiés aux espèces à l'aide de la fonction `table`. On pourrait également les combiner dans un même tableau avec la fonction `data.frame`.
```{r}

table(d$Species,k$cluster)

```

On voit que le groupe 1 semble très bien correspondre à l'espèce *setosa* et les deux autres groupes correspondent assez bien aux deux autres espèces, quoiqu'il y a un certain niveau de confusion entre les deux espèces. Évidemment, ici, on connaît les groupements à l'avance. Ceci est uniquement pour illustrer une méthode de classification qui permettrait éventuellement de classifier des sites ou des objets sur la base de variables quantitatives.

On pourrait également essayer la classification hiérarchique avec la fonction `hclust` et appliquer les différentes commandes utilisées dans l'exemple pour établir de grands groupes et illustrer les résultats.

```{r,fig.width=11}

dis <- dist(d[,-5], method = "euclidean") # on calcule la distance entre les objets
h <- hclust(dis) # on les classifie
plot(h,labels=d$Species,cex=0.5) # on illustre les résultats en réduisant la taille du texte
groups <- cutree(h, k=3) # on crée 3 grands groupes
rect.hclust(h, k=3, border="red") # on ajoute ces groupes sur l'arbre de classification

```

On obtient des résultats assez similaires à la méthode k-means, mais ici la classification est hiérarchique. Ceci n'est qu'un exercice de recherche de fonctions pour illustrer les méthodes de classification. Il faudrait évidemment faire des recherches plus approfondies pour identifier les meilleures méthodes adaptées à notre problème. Un point important ignoré lors de nos classification est qu'il aurait fallu s'assurer de standardiser (*scaler*) nos données avant la classification afin de donner le même poids à toutes les variables.

#### 3.

Il existe plusieurs fonctions pour effectuer des PCA, mais nous allons utiliser la fonction `rda` du package vegan, un package classique pour les analyses multivariées. Remarquez que nous pouvons utiliser l'argument `scale` pour standardiser les variables afin de ne pas donner plus de poids à certaines variables dans l'analyse.
```{r,warning=FALSE,message=FALSE}

library(vegan)

m<-rda(d[,-5],scale=TRUE)
summary(m)

```

La majeure partie de la variation dans le jeu de données est capturée par le premier axe (i.e. 73%). Afin d'interpréter les résultats, il est essentiel d'illustrer les résultats dans un graphique. La construction de graphiques élégants pour illustrer les ordinations n'est pas toujours évidente et les fonctions de bases ne donnent pas toujours les plus belles illustrations. Pour ce faire, vous pouvez vous inspirer de ce que vous trouvez sur internet. Voici un [article de blog](https://www.fromthebottomoftheheap.net/2012/04/11/customising-vegans-ordination-plots/) qui donne différentes méthodes pour améliorer l'illustration d'une ordination à partir de `rda`. Bien que cela représente plus de travail, sachez qu'il est généralement possible d'extraire les coordonées de toutes les valeurs utilisées afin de produire les graphiques, ce qui donne toute la flexibilité possible pour l'illustration des résultats. Ici, nous nous contenterons de graphiques relativement simples sur lesquels nous illustrerons les différentes espèces. Remarquez que nous utilisons un vecteur de couleurs que nous indexons par la suite en se basant sur le fait que la colonne `d$Species` est considérée comme un `factor`.
```{r}

col<-c("tomato4","orange","darkblue")

biplot(m,scaling=1,display = c("sites","species"),type = c("text","points"),col=c("white","black"),main="Scaling 1")
points(m,scaling=1,col=col[as.integer(d$Species)],pch=1)
legend("bottomright",col=col,pch=1,legend=levels(d$Species))


biplot(m,scaling=2,display = c("sites","species"),type = c("text","points"),col=c("white","black"),main="Scaling 2")
points(m,scaling=2,col=col[as.integer(d$Species)],pch=1)
legend("bottomright",col=col,pch=1,legend=levels(d$Species))

```

L'axe 1 est surtout déterminé par les dimensions des pétales et dans une moindre mesure par la longueur des sépales. Quant au second axe, il est surtout déterminé par la largeur des sépales. En consultant le premier graphique, le groupe *setosa* semble se distinguer de façon assez marquée par rapport aux deux autres espèces. Avec le second graphique, on constate que les dimensions des pétales sont très corrélées, alors que ce n'est pas du tout le cas pour les dimensions des sépales.

<!--

# Atelier 8

Quelles questions pouvez-vous vous poser avec le jeu de données *aravo* du package **ade4**? Est-ce que des variables environnementales permettent d'expliquer les variations en composition de plantes alpines (CCA)? Réalisez et illustrer quelques analyses multivariées afin d'explorer ce jeu de données. Vous pouvez vous inspirer du site [GUSTA ME](https://sites.google.com/site/mb3gustame/) (donné en référence dans les liens utiles plus bas) et de son *wizard* sur les analyses contraintes ou encore de l'information contenue dans ce site [Analysis of community ecology data in R](https://www.davidzeleny.net/anadat-r/doku.php/en:ordination).

-->

<!--

# Méthodes / résultats

Articles à lire pour le cours du 20 mars.

[Predictors of malaria infection in a wild bird population: landscape-level analyses reveal climatic and anthropogenic factors](http://onlinelibrary.wiley.com/doi/10.1111/1365-2656.12214/full)

[Latitudinal and altitudinal patterns of plant community diversity on mountain summits across the tropical Andes](http://onlinelibrary.wiley.com/doi/10.1111/ecog.02567/abstract)

-->

# Travail de session

Le travail de session se déroulera en deux temps. La première partie (20%) consistera en l'établissement d'une méthodologie afin de répondre à une mise en situation et la seconde partie (80%) consistera en la rédaction d'un rapport sous forme d'article scientifique à partir d'une base de données en lien avec la première partie. Dans la plupart des cas, il y aura des différences entre la méthodologie proposée pour la mise en situation et la méthodologie utilisée pour récolter les données fournies. Dans ce cas, il faudra adapter votre méthodologie décrite dans la partie 2 du travail afin de refléter la méthodologie utilisée. 

## Partie I

La première partie (20%) devra comprendre la méthodologie proposée pour récolter et analyser les données. Plus spécifiquement, vous devrez présenter un plan d’échantillonnage en plus d’indiquer quelles mesures seront prises sur le terrain. Une ou des méthodes d'analyses statistiques devront également être proposées. Cette partie du travail devra être remise par courriel au plus tard le **mardi 25 février à 17h**. 

Comment-allez vous répondre à cette mise en situation? Quel sera votre plan d'échantillonnage? Quelles seront les variables que vous utiliserez? Quelles méthodes envisagez-vous utiliser pour analyser les données récoltées? La méthodologie proposée devrait pouvoir être exposée en un maximum de **2 pages**. Puisque certains éléments sont inconnus, il sera bien sûr impossible de détailler tous les aspects de votre méthodologie. Le travail proposé ici a surtout pour objectif de vous faire réfléchir à un design d'étude vous permettant de répondre à une question de nature écologique. 

Vous devrez probablement vous inspirer de la littérature scientifique afin d'identifier les variables à utiliser et établir votre plan d'échantillonnage. Afin de limiter l'éventail des possibilités, il serait préférable de vous limiter à identifier un maximum de 4 ou 5 variables à utiliser. En effet, de multiples variables pourraient être mesurées, mais il s'agit surtout ici d'identifier quelques variables pertinentes et surtout d'être capable de développer et d'exposer un plan d'échantillonnage pour répondre à une question donnée. De la même façon, il n'est pas nécessaire de mentionner que vous allez inventorier des milliers de sites pour répondre à la question. Il s'agit d'utiliser un nombre de stations ou un échantillonnage suffisant en fonction de la question ou du nombre de variables étudiées. Ceci n'est pas toujours évident à évaluer et vous devrez vous fier à votre jugement pour déterminer l'étendue de votre échantillonnage. Vous devrez également choisir un endroit où réaliser votre plan d'échantillonnage en fonction de votre question. 

L'important dans cette section n'est pas de remplir les 2 pages, mais plutôt de décrire suffisament les différents aspects votre méthodologie pour qu'un lecteur potentiel puisse reproduire votre étude.

## Partie II

Pour la seconde partie du travail (80%), chaque étudiant ou étudiante recevra une base de données en lien avec ce qui a été proposé dans la première partie du travail. Elle ou il devra réaliser les analyses, les interpréter et présenter les résultats dans un bref rapport écrit qui prendra la forme d'un article scientifique comprenant les éléments suivants :

- **Introduction** : Courte introduction présentant et mettant en contexte la question posée et les
hypothèses biologiques.
- **Méthodologie** : Description des méthodes et des données récoltées et description et
justification des analyses statistiques effectuées.
- **Résultats** : Présentation des résultats accompagnée de graphiques et/ou de tableaux.
- **Discussion** : Courte explication et interprétation des résultats et de leur signification
biologique.
- **Références** : Un minimum de cinq références (**articles scientifiques**) devront être utilisées pour
mettre en contexte la problématique et/ou interpréter les résultats.
- **Annexe** : Code R (propre!) utilisé pour effectuer les manipulations de données, les analyses statistiques et les graphiques. Ce code devrait contenir toutes les lignes de programmation permettant de reproduire votre travail à partir de votre base de données jusqu'aux graphiques présentés. Les lignes de codes inutiles, exploratoires ou générant des erreurs devraient être éliminées. Les parties plus compliquées de votre code devraient inclure des commentaires expliquant ce qui est effectué.

Pour ceux désirant utiliser leur propre jeu de données, vous devrez énoncer vous même votre propre mise en situation et m'en faire part au plus tard au cours du mardi 26 février par courriel ou en personne en me montrant également la base de données qui sera utilisée (ou un extrait). Votre travail au complet ne devrait pas prendre plus de **10 pages**. Ce travail est à remettre au plus tard le **vendredi 20 mars à 17h**.

<!-- 

Clarifier les références partie 1 vs partie 2 

Clarifier les sections à inclure

Ajouter au cours une section sur le design expérimental en écologie avec des exemples provenant des travaux des étudiants

Importance des variables, de l'échelle donner exemple de paramètres physico dans un petit lac qui ne varie pas

Donner exemple de variable dans une analyse de prévalence qui ne varie pas (ex température, altitude, etc.)

Toujours se demander, est-ce que nos variables varient? Est-ce que l'échelle à laquelle on mesure les choses fait du sens

-->

## Mises en situation

<br>

**1. Composition du paysage, Grand-duc d'Amérique et occurrence de la Chouette rayée**

Quelles sont les caractéristiques du paysage affectant la présence de la Chouette rayée (*i.e.* une espèce de hibou, *Strix varia*) dans le sud du Québec?

<!--

Les données ont été récoltées en Montérégie et en Estrie. À chaque site, trois stations d'écoute d'une durée de 10 minutes ont été effectuées au courant de la saison propice à la détection. L'espèce était considérée présente lorsqu'il y avait au moins une détection. Voici la base de données [chouette](https://raw.githubusercontent.com/frousseu/ECL749/master/data/chouette.csv) et une description des variables. 

- **site**: station d'écoute
- **year**: année de visite
- **rayon**: rayon auquel les % ont été mesurés
- **for_feuil**: % de forêt feuillue
- **for_con**: % de forêt coniférienne
- **for_mix**: % de forêt mixte
- **for_pert**: % de forêt perturbée ou secondaire
- **cult_int**: % de culture intensive (maïs ou soya)
- **cult_ext**: % de culture extensive (pâturage, céréales, cultures maraîchères)
- **GDApres**: Grand-duc d'Amérique présent ou absent (1/0)
- **CRpres**: Chouette rayée présente ou absente (1/0)

-->

<br>

**2. Richesse ichtyologique dans les récif coraliens**

Quelles sont les variables influençant la richesse en poissons dans les récifs coraliens?

<!--

Ces données ont été récoltées dans différentes sections de sites dans les Caraïbes. Le nombre d'espèces de poissons a été évalué à partir de 5 heures d'observations à chaque endroit dans des moments propices. Voici la base de données [poissons_coraux](https://raw.githubusercontent.com/frousseu/ECL749/master/data/poissons_coraux.csv) et une description des variables:

- **nbpoissons**: nb d'espèces de poissons détectées
- **nbcoraux**: nb d'espèces de coraux détectées
- **nbgrandscoraux**: nb d'espèces de coraux de grande taille ( > 50cm )
- **complexité**: indice de complexité du relief variant de 1 (peu complexe) à 5 (très complexe) (estimation visuelle)
- **pente**: pente générale de la section de récif échantillonnée (degrés)
- **site**: site d'échantillonnage

-->

<br>

**3. Diversité aviaire, forêt et fragmentation en milieu tropical**

Quel est l'effet de la fragmentation forestière sur la richesse aviaire en milieu tropical?

<!--

Ces données ont été récoltées dans différents sites fragmentés d'une région du Costa Rica. Le nombre d'espèces d'oiseaux à l'intérieur de chaque fragment a été évalué en visitant chaque parcelle pour un minimum de 4h chacune et jusqu'à ce que le nb de nouvelles espèces rencontrées n'augmente pas pendant une période de deux heures. Les visites ont été effectuées pendant la période de reproduction et à des moments propices (*i.e.* tôt le matin, conditions climatiques clémentes) pour l'observation. Voici la base de données [fragmentation_aviaire](https://raw.githubusercontent.com/frousseu/ECL749/master/data/fragmentation_aviaire.csv) et une description des variables:

- **alpha**: nb d'espèces d'oiseaux répertoriées
- **alti**: altitude du site
- **super**: superficie du fragment (hectares)
- **frag**: type de fragment (*small* ou *large*)
- **foret**: % de superficie en forêt dans un rayon de 1000m
- **vieille**: % de superficie en vieille forêt dans un rayon de 1000m
- **site**: numéro du site

-->

<br>

**4. L'abondance des moineaux dans un contexte agricole**

Quels sont les éléments du paysage affectant l'abondance du Moineau domestique (*Passer domesticus*) en milieu agricole dans le sud du Québec?

<!--

Ces données ont été récoltées à diverses fermes de la Montérégie et de l'Estrie. Des stations d'écoute d'une durée de 10 minutes ont effectuées à chaque ferme tôt le matin pendant les mois de mai et juin. Voici la base de données [moineaux](https://raw.githubusercontent.com/frousseu/ECL749/master/data/moineaux.csv) et une description des variables:

- **ferme**: identifiant de la ferme
- **vis**: numéro de la visite
- **abHOSP**: nombre de moineaux détectés
- **int500**: % de culture intensive dans un rayon de 500m (maïs ou soya)
- **ext500**: % de culture extensive dans un rayon de 500m (pâturage, céréales, cultures maraîchères)
- **for500**: % de forêt dans un rayon de 500m
- **eau500**: % d'eau (surface) dans un rayon de 500m
- **supbat500**: % de bâtiments (surface) dans un rayon de 500m
- **peribat500m**: périmètre total de bâtiments dans un rayon de 500m (en mètres)
- **perim500km**: périmètre total de bâtiments dans un rayon de 500m (en km)

-->

<br>

**5. La diversité des papillons dans les prairies naturelles**

Quelles sont les caractéristiques de la végétation affectant la diversité en espèces de papillons dans les prairies naturelles?

<!--

Ces données ont été récoltées à divers sites dans les prairies américaines. À chaque site, 5 transects de 100 m de récolte active (avec un filet) et 2 nuitée de récolte passive (avec un drap et de la lumière) ont été effectuées pendant les mois de juin et juillet. Voici la base de données [papillons](https://raw.githubusercontent.com/frousseu/ECL749/master/data/papillons.csv) et une description des variables:

- **site**: site de récolte
- **habitat**: type d'habitat (champs de foin ou pâturage, graminées courtes, graminés grandes, mixtes)
- **batiment**: % de superficie en batiment
- **urbain**: % de superficie en zone urbaine
- **year**: année
- **julien**: jour julien
- **nbsp**: nb d'espèces de papillons

<br><br>

-->

# Liens utiles

Ici, je tente de regrouper différentes ressources qui vous seront presque assurément utiles lors de la réalisation de vos projets. Si vous découvrez des éléments qui seraient pertinents à ajouter, vous pouvez m'en faire part. Afin de ne pas "noyer le poisson", j'essaie de ne mentionner que les ressources les plus importantes.

## Ressources en ligne

### R

[Quick-R](https://www.statmethods.net/index.html): site d'introduction à R

[Base R Cheat Sheet](http://github.com/rstudio/cheatsheets/raw/master/base-r.pdf): Guide mémoire pour les fonctions de base de R

[RStudio Cheat Sheets](https://www.rstudio.com/resources/cheatsheets/): Divers guides mémoires pour R sur différents sujets 

[R Spatial](http://www.rspatial.org/): Introduction à R pour l'analyse et la modélisation de données spatiales

### Statistiques

[GLMM FAQ](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html): Guide pour l'utilisation des modèles mixtes avec R

[GUSTA ME](https://sites.google.com/site/mb3gustame/): GUide to STatistical Analysis in Microbial Ecology. Un guide assez complet et très *user friendly* sur les analyses statistiques, surtout multivariées, comprenant l'explication, l'utilisation, l'interprétation, les suppositions et des exemples de plusieurs types d'analyses multivariées. Bien que le site soit orienté vers l'écologie microbienne, il est pertinent pour les biologistes et les écologistes en général.

[Analysis of community ecology data in R](https://www.davidzeleny.net/anadat-r/doku.php/en:start): Un autre site d'introduction aux analyses multivariées très utile. 

[Ordination Methods for Ecologists](http://ordination.okstate.edu/): Site abordant plusieurs sujets liés à l'ordination.

[Ateliers R du CSBQ](https://qcbs.ca/wiki/r): Ateliers en ligne du CSBQ concernant plusieurs sujets liés à R (manipulation de données, programmation, ggplot) ou aux statistiques (glm, modèles mixtes, analyses multivariées, etc.) 

## Ressources publiées

### Articles 

[A protocol for data exploration to avoid common statistical problems](https://doi.org/10.1111/j.2041-210X.2009.00001.x)

[A protocol for conducting and presenting results of regression-type analyses](https://doi.org/10.1111/2041-210X.12577)

[Applied statistics in ecology: common pitfalls and simple solutions](https://doi.org/10.1890/ES13-00160.1)

[Generalized linear mixed models: a practical guide for ecology and evolution](https://doi.org/10.1016/j.tree.2008.10.008)

[A brief introduction to mixed effects modelling and multi-model inference in ecology](https://doi.org/10.7717/peerj.4794)

[Application of multivariate statistical techniques in microbial ecology](https://doi.org/10.1111/mec.13536)

[Multivariate analyses in microbial ecology](https://doi.org/10.1111/j.1574-6941.2007.00375.x)

### Livres

Plusieurs des livres suivants sont disponibles à la bibliothèque et certains sont disponibles en pdf sur internet.

[The R Book](https://www.wiley.com/en-us/The+R+Book%2C+2nd+Edition-p-9780470973929): Un classique très complet pour l'introduction à R et aux analyses statistiques avec R.

[Introductory statistics with R](http://www.springer.com/gp/book/9780387790534)

[Statistics for terrified biologists](https://www.wiley.com/en-us/Statistics+for+Terrified+Biologists-p-9781405149563)

[La série des *Zuur*](http://www.highstat.com/index.php/books): La série de *Highland Statistics* est très orientée sur la pratique et couvre plusieurs analyases en écologie, surtout en ce qui a trait à la modélisation (GLM, GLMM, GAM, etc.)

[Numerical Ecology with R](http://adn.biol.umontreal.ca/~numericalecology/numecolR/): Les versions anciennes sont disponibles en ligne en verison pdf.

[Numerical Ecology](https://elsevier-internet-dev.squiz.co.uk/books/numerical-ecology/legendre/978-0-444-53868-0): Un classique sur plusieurs types d'analyses en écologie, particulièrement les analyses multivariées. Les versions anciennes sont disponibles en ligne en verison pdf.

## Forums

Quelle que soit votre question sur R ou sur les statistiques, il est fort probable que celle-ci ait déjà été posée et répondue sur l'un de ces forums. Il s'agit d'utiliser les bons mots clés et de bien explorer les questions reliées.

[Stack Overflow](https://stackoverflow.com/questions/tagged/r): Programmation avec R (questions portant le tag "R").

[Cross Validated](https://stats.stackexchange.com/): Questions concernant les statistiques.




```{r, eval=FALSE, include=FALSE}

# formule

# argument data vs. $ vs création des vecteurs indépendants

# read.csv avec mauvais séparateur égal une seule colonne

# transformation des variables numériques en facteur

# subset pour créer le graphique

# aov vs lm

# summary.lm vs summary.aov

# boxplot pour variable cat et non num

# pourquoi binom.test vs khi2?

# exemple analyse de puissance

# tableau des tests classiques

# moins d'exemples de khi2

# anova le premier exemple ne devrait avoir qu'un seul facteur

# dire dans une boîte verte explicitement qu'on compare au niveau de référence

# mieux distingué le test global sur la variance et celui sur les coefficients

# parler de la minimisation des carrés

```



```{r, eval=FALSE, include=FALSE,echo=FALSE} 
d<-read.table("C:/Users/rouf1703/Downloads/ZuurDataMixedModelling/Sparrows.txt",header=TRUE)
d<-read.table("U:/2018/2018/Ateliers/sparrows.txt",header=TRUE)
library(plyr)
ddply(d,.(Sex),function(i){mean(i$wingcrd,na.rm=TRUE)})
d$Sex<-ifelse(d$Sex==4,"m","f")
write.table(d[sample(1:nrow(d),87),c("Sex","wingcrd","wt")],"U:/2018/2018/Ateliers/sparrows.txt",row.names=FALSE)
``` 



